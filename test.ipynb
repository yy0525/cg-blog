{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline\n",
        "[run_training_dpo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "N3OgIevnjdjo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "418__XIwjdjq"
      },
      "source": [
        "# Stage 1: Continue Pretraining\n",
        "\n",
        "第一阶段：PT(Continue PreTraining)增量预训练，在海量领域文本数据上二次预训练GPT模型，以适配领域数据分布\n",
        "\n",
        "注意：\n",
        "1. 此阶段是可选的，如果你没有海量领域文本，可以跳过此阶段，直接进行SFT阶段的有监督微调\n",
        "2. 我实验发现：做领域知识注入，SFT比PT更高效，也可以跳过PT阶段\n",
        "\n",
        "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDPsgMQjdjr"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m`\n",
        "2. 数据集：PT阶段使用的是中文天龙八部小说部分文本和英文书籍部分文本，位于`data/pretrain`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "ZTX4oSy9jdjr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX3nxK3djdjr"
      },
      "source": [
        "## 配置运行环境\n",
        "\n",
        "本地执行可注释以下配置环境的命令，colab执行要打开注释，用于配置环境\n",
        "\n",
        "colab建议使用T4 GPU训练，设置方式：`代码执行程序 -> 更改运行时类型 -> 运行时类型：Python3，硬件加速器：GPU，GPU类型：T4 -> 保存`\n",
        "\n",
        "步骤：\n",
        "1. 下载最新代码到本地\n",
        "2. 安装依赖包\n",
        "\n",
        "依赖包如下，保证最新版本：\n",
        "\n",
        "```\n",
        "loguru\n",
        "transformers\n",
        "sentencepiece\n",
        "datasets\n",
        "tensorboard\n",
        "tqdm\n",
        "peft\n",
        "trl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VAcKw6F8jdjr",
        "outputId": "7794c1f0-8777-4557-e5a9-8e6406490f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedicalGPT'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 69 (delta 11), reused 38 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (69/69), 8.07 MiB | 12.10 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/MedicalGPT\n",
            "build_domain_tokenizer.py          dpo_training.py             README.md\n",
            "chatpdf.py                         fastapi_server_demo.py      requirements.txt\n",
            "CITATION.cff                       gradio_demo.py              reward_modeling.py\n",
            "_config.yml                        inference_multigpu_demo.py  run_dpo.sh\n",
            "CONTRIBUTING.md                    inference.py                run_ppo.sh\n",
            "convert_dataset.py                 LICENSE                     run_pt.sh\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                              merge_peft_adapter.py       run_rm.sh\n",
            "deepspeed_zero_stage2_config.json  merge_tokenizers.py         run_sft.sh\n",
            "deepspeed_zero_stage3_config.json  ppo_training.py             run_training_dpo_pipeline.ipynb\n",
            "DISCLAIMER                         pretraining.py              run_training_ppo_pipeline.ipynb\n",
            "\u001b[01;34mdocs\u001b[0m/                              README_EN.md                supervised_finetuning.py\n",
            "Collecting loguru (from -r requirements.txt (line 1))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.38.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.1.99)\n",
            "Collecting datasets>=2.14.6 (from -r requirements.txt (line 4))\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.15.2)\n",
            "Collecting peft>=0.7.0 (from -r requirements.txt (line 8))\n",
            "  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.21.0 (from -r requirements.txt (line 9))\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl>=0.7.11 (from -r requirements.txt (line 10))\n",
            "  Downloading trl-0.7.11-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->-r requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r requirements.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.14.6->-r requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 4)) (3.9.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft>=0.7.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft>=0.7.0->-r requirements.txt (line 8)) (2.1.0+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl>=0.7.11->-r requirements.txt (line 10))\n",
            "  Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.37.2->-r requirements.txt (line 2)) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.2->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.2->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.2->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.37.2->-r requirements.txt (line 2)) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.7.0->-r requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.7.0->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.7.0->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft>=0.7.0->-r requirements.txt (line 8)) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10))\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10)) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft>=0.7.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11->-r requirements.txt (line 10)) (0.1.2)\n",
            "Installing collected packages: shtab, loguru, docstring-parser, dill, multiprocess, tyro, accelerate, datasets, trl, peft\n",
            "Successfully installed accelerate-0.27.2 datasets-2.18.0 dill-0.3.8 docstring-parser-0.15 loguru-0.7.2 multiprocess-0.70.16 peft-0.9.0 shtab-1.7.1 trl-0.7.11 tyro-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
        "%cd MedicalGPT\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrXfU1Kejdjs"
      },
      "source": [
        "## Stage1 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果\n",
        "\n",
        "**以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uafrn620jdjs",
        "outputId": "e5248219-f3a4-4b3d-8e8b-ff659a34e2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_article_tail500.txt  fever.txt  tianlongbabu.txt\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/pretrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-08 05:39:22.691589: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-08 05:39:22.691665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-08 05:39:22.693016: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-08 05:39:23.706874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-03-08 05:39:24.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mModel args: ModelArguments(model_type='bloom', model_name_or_path='bigscience/bloomz-560m', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:24.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:24.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=50,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-pt-v1/runs/Mar08_05-39-24_5f33b1e3353c,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=outputs-pt-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=3,\n",
            "per_device_train_batch_size=3,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-pt-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:24.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m381\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:24.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\u001b[0m\n",
            "tokenizer_config.json: 100% 222/222 [00:00<00:00, 1.14MB/s]\n",
            "tokenizer.json: 100% 14.5M/14.5M [00:00<00:00, 287MB/s]\n",
            "special_tokens_map.json: 100% 85.0/85.0 [00:00<00:00, 464kB/s]\n",
            "\u001b[32m2024-03-08 05:39:27.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m492\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/fever.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt']\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:27.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m502\u001b[0m - \u001b[1meval files: ['./data/pretrain/fever.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt']\u001b[0m\n",
            "Generating train split: 3876 examples [00:00, 174352.20 examples/s]\n",
            "Generating validation split: 3876 examples [00:00, 475201.61 examples/s]\n",
            "\u001b[32m2024-03-08 05:39:28.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m534\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "})\u001b[0m\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:00<00:00, 5820.02 examples/s]\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:00<00:00, 6709.26 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 6416.85 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 5283.07 examples/s]\n",
            "\u001b[32m2024-03-08 05:39:31.048\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m597\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2465\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:31.048\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m598\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:31.050\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m599\u001b[0m - \u001b[34m\u001b[1m第一章论\n",
            "传染病是指由病原微生物，如朊粒、病毒、衣原体、立克次体、支原体（mycoplasma)细菌真菌、螺旋体和寄生虫，如原虫、蠕虫、医学昆虫感染人体后产生的有传染性、在一定条件下可造成流行的疾病。感染性疾病是指由病原体感染所致的疾病，包括传染病和非传染性感染性疾病。\n",
            "传染病学是一门研究各种传染病在人体内外发生、发展、传播、诊断、治疗和预防规律的学科。重点研究各种传染病的发病机制、临床表现、诊断和治疗方法，同时\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:31.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m611\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:31.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m612\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:31.055\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m613\u001b[0m - \u001b[34m\u001b[1m第一章论\n",
            "传染病是指由病原微生物，如朊粒、病毒、衣原体、立克次体、支原体（mycoplasma)细菌真菌、螺旋体和寄生虫，如原虫、蠕虫、医学昆虫感染人体后产生的有传染性、在一定条件下可造成流行的疾病。感染性疾病是指由病原体感染所致的疾病，包括传染病和非传染性感染性疾病。\n",
            "传染病学是一门研究各种传染病在人体内外发生、发展、传播、诊断、治疗和预防规律的学科。重点研究各种传染病的发病机制、临床表现、诊断和治疗方法，同时\u001b[0m\n",
            "config.json: 100% 715/715 [00:00<00:00, 2.47MB/s]\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "model.safetensors: 100% 1.12G/1.12G [00:04<00:00, 264MB/s]\n",
            "\u001b[32m2024-03-08 05:39:37.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m672\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:37.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m677\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:37.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m690\u001b[0m - \u001b[1mPeft target_modules: ['dense', 'dense_4h_to_h', 'dense_h_to_4h', 'query_key_value']\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:37.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m691\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 3,145,728 || all params: 562,360,320 || trainable%: 0.5593794384354857\n",
            "\u001b[32m2024-03-08 05:39:37.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m736\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2024-03-08 05:39:38.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m737\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[   814,   2382,   1114,  14876,  14982,   4505,  11809,    773,  89994,\n",
            "          21085,    777,   2336,    355, 181636,   4247, 227353,    355,  11860,\n",
            "          39976, 102925,   1625,  18582,   7168,  40955,   2498,  74356,  17074,\n",
            "           1625,   1170,   4247,    355,   3026,   9062,   1625,  87863, 176247,\n",
            "           4587, 115976,  11279,   1572,    355, 162582,  10202,   6323,  16339,\n",
            "            355,   6323,  16339, 200390,  27619,   3033, 166137,   7168, 185710,\n",
            "          72859,   4589,    355,   1194,  56266,  16523,   4918,    237,   1262,\n",
            "           2044,  17074,  90707,    420,    982,  14876,  14982,   2405,   3101,\n",
            "          10202,  55049,  90707,  10468,   2382,  12395,  87707,   7606,   3033,\n",
            "         196327,    420,    982,  27619, 155906,   1572,    355, 143800,   5122,\n",
            "          11809,    773,  89994, 185710,  72859,   2014,  55049,   2336,    355,\n",
            "         159434,  11809,    773,  89994,   3242,  51307,  87863, 176247,   4587,\n",
            "          17096,    355, 103190,  14876,  14982,   3033,   1187,    355, 229902,\n",
            "           2884, 221823,  15361,    420,  18020, 210451,    355,   4567,  31218,\n",
            "            746,   5472],\n",
            "        [  6323,   9663,    355,   1194,   5315,  30325,  30771,    355,   1190,\n",
            "           4567,   4677,   7848,   5242,   3033,   3569,   9311,   2106,  27515,\n",
            "           2279,  30325,    726,    355,   4137,   5585,   1586,  10169,   8888,\n",
            "         215545,  44997,  50881,  22181,  44991,    355,   1731,   4294,  13474,\n",
            "          88163,   1518,   1187, 168034,  59274,   6664,   2129,  22262,    355,\n",
            "           3105,   1412, 215545,   3244, 245824,    594,   2106,   9311,  13161,\n",
            "            594,    954,   6621,    594,   2203,   1995,    594,   9311,  19171,\n",
            "            594,    773, 213570,    594,   3630,  15755,   3999,    355, 156118,\n",
            "           4137,   5585,    355,   1586, 228367,   3233,    373,   5242,   1995,\n",
            "          10608,    726,  44991,    773,   8502,   1203,    420,    982,    189,\n",
            "         170578,   6553,   7408,   3578,   8103,   2524,   4137,   5585,    355,\n",
            "         228367,   3233,   3225,   3562,    355,   9699,    101,   9699,    101,\n",
            "           8577,   7179,    355,   4137,   5585,   1586,   5242,   1995,  10608,\n",
            "            726,  44991,    773,   1424,    121,  58014, 151298,    814,  73478,\n",
            "          20024,  75305],\n",
            "        [   644, 177615,    420,   2382, 209045,  13474,  13474,    373,  25410,\n",
            "            842,   1848,  40151,   9006,   1190,    355,  26769,   1190,  11354,\n",
            "           1586, 121454, 137730,    355,   2808,  25267, 116434,   7046,  89026,\n",
            "            355,   1194,   2808,   4719,  73549,  35019,  10468,    982,    189,\n",
            "           4697,  33539,  19270,   1412,   8757,    355,  24572,   2473,  25410,\n",
            "         131520, 222034,  24913,  88688,    355, 224406,   4567,   5496,    355,\n",
            "           6840, 172369,   1124,   5242,  11354,   1586, 121454,    726,   3244,\n",
            "           1828,   2498,   7046,  89026,  49120,  80543,  14675, 178493,    355,\n",
            "            842,   2342,   2950,   2808,   1190,    355,   1262,   4719,  15423,\n",
            "          25267,    420,  29967,   9006,   1600,   9006,  20950,    420,   5189,\n",
            "           1497,  45220,   5242,   1586,  66060,  22435,    355,  12516,   6632,\n",
            "          48407,    355,  21441,   5122, 221851,    726,    842,   1586,  66060,\n",
            "          22435,    355,  13135,  73549,  35019,    420,    982,    189,   2382,\n",
            "         209045,  25410,   4716,  22435,    746,  22435,  68322,   1190,  22435,\n",
            "           5759,  35206]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[   814,   2382,   1114,  14876,  14982,   4505,  11809,    773,  89994,\n",
            "          21085,    777,   2336,    355, 181636,   4247, 227353,    355,  11860,\n",
            "          39976, 102925,   1625,  18582,   7168,  40955,   2498,  74356,  17074,\n",
            "           1625,   1170,   4247,    355,   3026,   9062,   1625,  87863, 176247,\n",
            "           4587, 115976,  11279,   1572,    355, 162582,  10202,   6323,  16339,\n",
            "            355,   6323,  16339, 200390,  27619,   3033, 166137,   7168, 185710,\n",
            "          72859,   4589,    355,   1194,  56266,  16523,   4918,    237,   1262,\n",
            "           2044,  17074,  90707,    420,    982,  14876,  14982,   2405,   3101,\n",
            "          10202,  55049,  90707,  10468,   2382,  12395,  87707,   7606,   3033,\n",
            "         196327,    420,    982,  27619, 155906,   1572,    355, 143800,   5122,\n",
            "          11809,    773,  89994, 185710,  72859,   2014,  55049,   2336,    355,\n",
            "         159434,  11809,    773,  89994,   3242,  51307,  87863, 176247,   4587,\n",
            "          17096,    355, 103190,  14876,  14982,   3033,   1187,    355, 229902,\n",
            "           2884, 221823,  15361,    420,  18020, 210451,    355,   4567,  31218,\n",
            "            746,   5472],\n",
            "        [  6323,   9663,    355,   1194,   5315,  30325,  30771,    355,   1190,\n",
            "           4567,   4677,   7848,   5242,   3033,   3569,   9311,   2106,  27515,\n",
            "           2279,  30325,    726,    355,   4137,   5585,   1586,  10169,   8888,\n",
            "         215545,  44997,  50881,  22181,  44991,    355,   1731,   4294,  13474,\n",
            "          88163,   1518,   1187, 168034,  59274,   6664,   2129,  22262,    355,\n",
            "           3105,   1412, 215545,   3244, 245824,    594,   2106,   9311,  13161,\n",
            "            594,    954,   6621,    594,   2203,   1995,    594,   9311,  19171,\n",
            "            594,    773, 213570,    594,   3630,  15755,   3999,    355, 156118,\n",
            "           4137,   5585,    355,   1586, 228367,   3233,    373,   5242,   1995,\n",
            "          10608,    726,  44991,    773,   8502,   1203,    420,    982,    189,\n",
            "         170578,   6553,   7408,   3578,   8103,   2524,   4137,   5585,    355,\n",
            "         228367,   3233,   3225,   3562,    355,   9699,    101,   9699,    101,\n",
            "           8577,   7179,    355,   4137,   5585,   1586,   5242,   1995,  10608,\n",
            "            726,  44991,    773,   1424,    121,  58014, 151298,    814,  73478,\n",
            "          20024,  75305],\n",
            "        [   644, 177615,    420,   2382, 209045,  13474,  13474,    373,  25410,\n",
            "            842,   1848,  40151,   9006,   1190,    355,  26769,   1190,  11354,\n",
            "           1586, 121454, 137730,    355,   2808,  25267, 116434,   7046,  89026,\n",
            "            355,   1194,   2808,   4719,  73549,  35019,  10468,    982,    189,\n",
            "           4697,  33539,  19270,   1412,   8757,    355,  24572,   2473,  25410,\n",
            "         131520, 222034,  24913,  88688,    355, 224406,   4567,   5496,    355,\n",
            "           6840, 172369,   1124,   5242,  11354,   1586, 121454,    726,   3244,\n",
            "           1828,   2498,   7046,  89026,  49120,  80543,  14675, 178493,    355,\n",
            "            842,   2342,   2950,   2808,   1190,    355,   1262,   4719,  15423,\n",
            "          25267,    420,  29967,   9006,   1600,   9006,  20950,    420,   5189,\n",
            "           1497,  45220,   5242,   1586,  66060,  22435,    355,  12516,   6632,\n",
            "          48407,    355,  21441,   5122, 221851,    726,    842,   1586,  66060,\n",
            "          22435,    355,  13135,  73549,  35019,    420,    982,    189,   2382,\n",
            "         209045,  25410,   4716,  22435,    746,  22435,  68322,   1190,  22435,\n",
            "           5759,  35206]], device='cuda:0')}\u001b[0m\n",
            "  0% 0/822 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 5.0909, 'grad_norm': 1.8604791164398193, 'learning_rate': 4.7619047619047615e-06, 'epoch': 0.0}\n",
            "{'loss': 4.8707, 'grad_norm': 1.8043296337127686, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.01}\n",
            "{'loss': 4.402, 'grad_norm': 1.5697674751281738, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.02}\n",
            "{'loss': 4.5504, 'grad_norm': 2.1044044494628906, 'learning_rate': 0.00014285714285714287, 'epoch': 0.04}\n",
            "{'loss': 4.4314, 'grad_norm': 2.7044577598571777, 'learning_rate': 0.00019047619047619048, 'epoch': 0.05}\n",
            "{'loss': 4.438, 'grad_norm': 2.746748208999634, 'learning_rate': 0.00019794871794871796, 'epoch': 0.06}\n",
            "  6% 50/822 [00:11<02:26,  5.27it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.5853569507598877, 'eval_accuracy': 0.347244094488189, 'eval_runtime': 0.2619, 'eval_samples_per_second': 38.178, 'eval_steps_per_second': 15.271, 'epoch': 0.06}\n",
            "  6% 50/822 [00:11<02:26,  5.27it/s]\n",
            "100% 4/4 [00:00<00:00, 25.64it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 4.2796, 'grad_norm': 2.510512590408325, 'learning_rate': 0.0001953846153846154, 'epoch': 0.07}\n",
            "{'loss': 4.3684, 'grad_norm': 2.549001932144165, 'learning_rate': 0.00019282051282051282, 'epoch': 0.09}\n",
            "{'loss': 4.1404, 'grad_norm': 2.3627779483795166, 'learning_rate': 0.00019025641025641025, 'epoch': 0.1}\n",
            "{'loss': 4.1907, 'grad_norm': 2.6092774868011475, 'learning_rate': 0.0001876923076923077, 'epoch': 0.11}\n",
            "{'loss': 4.2501, 'grad_norm': 2.6281168460845947, 'learning_rate': 0.00018512820512820515, 'epoch': 0.12}\n",
            " 12% 100/822 [00:21<02:15,  5.33it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.4795100688934326, 'eval_accuracy': 0.3551181102362205, 'eval_runtime': 0.2144, 'eval_samples_per_second': 46.645, 'eval_steps_per_second': 18.658, 'epoch': 0.12}\n",
            " 12% 100/822 [00:21<02:15,  5.33it/s]\n",
            "100% 4/4 [00:00<00:00, 26.95it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 4.0283, 'grad_norm': 2.506732940673828, 'learning_rate': 0.00018256410256410258, 'epoch': 0.13}\n",
            "{'loss': 4.0779, 'grad_norm': 2.8644096851348877, 'learning_rate': 0.00018, 'epoch': 0.15}\n",
            "{'loss': 4.0795, 'grad_norm': 2.6117942333221436, 'learning_rate': 0.00017743589743589744, 'epoch': 0.16}\n",
            "{'loss': 4.1055, 'grad_norm': 2.648367404937744, 'learning_rate': 0.00017487179487179488, 'epoch': 0.17}\n",
            "{'loss': 3.9514, 'grad_norm': 2.324796199798584, 'learning_rate': 0.00017230769230769234, 'epoch': 0.18}\n",
            " 18% 150/822 [00:31<02:05,  5.34it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.47527813911438, 'eval_accuracy': 0.35039370078740156, 'eval_runtime': 0.2256, 'eval_samples_per_second': 44.322, 'eval_steps_per_second': 17.729, 'epoch': 0.18}\n",
            " 18% 150/822 [00:31<02:05,  5.34it/s]\n",
            "100% 4/4 [00:00<00:00, 26.64it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 4.0672, 'grad_norm': 2.958636999130249, 'learning_rate': 0.00016974358974358974, 'epoch': 0.19}\n",
            "{'loss': 4.1177, 'grad_norm': 2.6394431591033936, 'learning_rate': 0.0001671794871794872, 'epoch': 0.21}\n",
            "{'loss': 4.1728, 'grad_norm': 2.3976783752441406, 'learning_rate': 0.0001646153846153846, 'epoch': 0.22}\n",
            "{'loss': 4.1022, 'grad_norm': 2.7890617847442627, 'learning_rate': 0.00016205128205128207, 'epoch': 0.23}\n",
            "{'loss': 4.0593, 'grad_norm': 2.622368574142456, 'learning_rate': 0.0001594871794871795, 'epoch': 0.24}\n",
            " 24% 200/822 [00:41<02:01,  5.13it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.4106266498565674, 'eval_accuracy': 0.36299212598425196, 'eval_runtime': 0.2318, 'eval_samples_per_second': 43.142, 'eval_steps_per_second': 17.257, 'epoch': 0.24}\n",
            " 24% 200/822 [00:42<02:01,  5.13it/s]\n",
            "100% 4/4 [00:00<00:00, 25.55it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 4.1634, 'grad_norm': 2.4968032836914062, 'learning_rate': 0.00015692307692307693, 'epoch': 0.26}\n",
            "{'loss': 3.9516, 'grad_norm': 2.5554909706115723, 'learning_rate': 0.00015435897435897436, 'epoch': 0.27}\n",
            "{'loss': 4.1006, 'grad_norm': 3.182783842086792, 'learning_rate': 0.0001517948717948718, 'epoch': 0.28}\n",
            "{'loss': 4.022, 'grad_norm': 2.7861509323120117, 'learning_rate': 0.00014923076923076923, 'epoch': 0.29}\n",
            "{'loss': 4.1434, 'grad_norm': 3.849311351776123, 'learning_rate': 0.00014666666666666666, 'epoch': 0.3}\n",
            " 30% 250/822 [00:52<02:14,  4.27it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.4347920417785645, 'eval_accuracy': 0.35669291338582676, 'eval_runtime': 0.221, 'eval_samples_per_second': 45.248, 'eval_steps_per_second': 18.099, 'epoch': 0.3}\n",
            " 30% 250/822 [00:52<02:14,  4.27it/s]\n",
            "100% 4/4 [00:00<00:00, 26.41it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9939, 'grad_norm': 3.2945189476013184, 'learning_rate': 0.0001441025641025641, 'epoch': 0.32}\n",
            "{'loss': 4.0352, 'grad_norm': 3.2098538875579834, 'learning_rate': 0.00014153846153846156, 'epoch': 0.33}\n",
            "{'loss': 4.0254, 'grad_norm': 2.941713333129883, 'learning_rate': 0.000138974358974359, 'epoch': 0.34}\n",
            "{'loss': 3.898, 'grad_norm': 2.1549222469329834, 'learning_rate': 0.00013641025641025642, 'epoch': 0.35}\n",
            "{'loss': 3.9743, 'grad_norm': 2.407010316848755, 'learning_rate': 0.00013384615384615385, 'epoch': 0.36}\n",
            " 36% 300/822 [01:02<02:19,  3.75it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.4055380821228027, 'eval_accuracy': 0.3700787401574803, 'eval_runtime': 0.2774, 'eval_samples_per_second': 36.049, 'eval_steps_per_second': 14.419, 'epoch': 0.36}\n",
            " 36% 300/822 [01:03<02:19,  3.75it/s]\n",
            "100% 4/4 [00:00<00:00, 22.16it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9713, 'grad_norm': 3.1419262886047363, 'learning_rate': 0.00013128205128205129, 'epoch': 0.38}\n",
            "{'loss': 3.9988, 'grad_norm': 2.592491626739502, 'learning_rate': 0.00012871794871794875, 'epoch': 0.39}\n",
            "{'loss': 4.0364, 'grad_norm': 2.7634437084198, 'learning_rate': 0.00012615384615384615, 'epoch': 0.4}\n",
            "{'loss': 3.9226, 'grad_norm': 3.095151424407959, 'learning_rate': 0.0001235897435897436, 'epoch': 0.41}\n",
            "{'loss': 3.9279, 'grad_norm': 2.7238776683807373, 'learning_rate': 0.00012102564102564103, 'epoch': 0.43}\n",
            " 43% 350/822 [01:13<01:31,  5.14it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.389378786087036, 'eval_accuracy': 0.3661417322834646, 'eval_runtime': 0.2253, 'eval_samples_per_second': 44.38, 'eval_steps_per_second': 17.752, 'epoch': 0.43}\n",
            " 43% 350/822 [01:13<01:31,  5.14it/s]\n",
            "100% 4/4 [00:00<00:00, 25.73it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9645, 'grad_norm': 3.154479742050171, 'learning_rate': 0.00011846153846153846, 'epoch': 0.44}\n",
            "{'loss': 3.8405, 'grad_norm': 3.0882904529571533, 'learning_rate': 0.00011589743589743591, 'epoch': 0.45}\n",
            "{'loss': 3.9576, 'grad_norm': 3.870523452758789, 'learning_rate': 0.00011333333333333334, 'epoch': 0.46}\n",
            "{'loss': 3.9779, 'grad_norm': 3.0094640254974365, 'learning_rate': 0.00011076923076923077, 'epoch': 0.47}\n",
            "{'loss': 3.9348, 'grad_norm': 2.4010229110717773, 'learning_rate': 0.0001082051282051282, 'epoch': 0.49}\n",
            " 49% 400/822 [01:23<01:21,  5.21it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.3731377124786377, 'eval_accuracy': 0.36929133858267715, 'eval_runtime': 0.2179, 'eval_samples_per_second': 45.887, 'eval_steps_per_second': 18.355, 'epoch': 0.49}\n",
            " 49% 400/822 [01:23<01:21,  5.21it/s]\n",
            "100% 4/4 [00:00<00:00, 26.03it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9692, 'grad_norm': 2.46911358833313, 'learning_rate': 0.00010564102564102565, 'epoch': 0.5}\n",
            "{'loss': 3.9819, 'grad_norm': 2.459763288497925, 'learning_rate': 0.00010307692307692307, 'epoch': 0.51}\n",
            "{'loss': 3.9733, 'grad_norm': 2.538194179534912, 'learning_rate': 0.00010051282051282052, 'epoch': 0.52}\n",
            "{'loss': 3.9026, 'grad_norm': 2.500264883041382, 'learning_rate': 9.794871794871795e-05, 'epoch': 0.54}\n",
            "{'loss': 3.9628, 'grad_norm': 2.6477699279785156, 'learning_rate': 9.53846153846154e-05, 'epoch': 0.55}\n",
            " 55% 450/822 [01:34<01:12,  5.14it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.342317581176758, 'eval_accuracy': 0.37716535433070864, 'eval_runtime': 0.2294, 'eval_samples_per_second': 43.589, 'eval_steps_per_second': 17.436, 'epoch': 0.55}\n",
            " 55% 450/822 [01:34<01:12,  5.14it/s]\n",
            "100% 4/4 [00:00<00:00, 25.49it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9375, 'grad_norm': 2.7575488090515137, 'learning_rate': 9.282051282051283e-05, 'epoch': 0.56}\n",
            "{'loss': 3.8452, 'grad_norm': 2.7175116539001465, 'learning_rate': 9.025641025641026e-05, 'epoch': 0.57}\n",
            "{'loss': 4.0042, 'grad_norm': 3.4818227291107178, 'learning_rate': 8.76923076923077e-05, 'epoch': 0.58}\n",
            "{'loss': 4.0524, 'grad_norm': 2.7306268215179443, 'learning_rate': 8.512820512820513e-05, 'epoch': 0.6}\n",
            "{'loss': 3.966, 'grad_norm': 2.84964919090271, 'learning_rate': 8.256410256410256e-05, 'epoch': 0.61}\n",
            " 61% 500/822 [01:44<01:02,  5.14it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.295231342315674, 'eval_accuracy': 0.38740157480314963, 'eval_runtime': 0.225, 'eval_samples_per_second': 44.439, 'eval_steps_per_second': 17.776, 'epoch': 0.61}\n",
            " 61% 500/822 [01:44<01:02,  5.14it/s]\n",
            "100% 4/4 [00:00<00:00, 25.99it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.8828, 'grad_norm': 3.646597385406494, 'learning_rate': 8e-05, 'epoch': 0.62}\n",
            "{'loss': 4.0016, 'grad_norm': 2.9982030391693115, 'learning_rate': 7.743589743589744e-05, 'epoch': 0.63}\n",
            "{'loss': 3.8025, 'grad_norm': 2.5690524578094482, 'learning_rate': 7.487179487179487e-05, 'epoch': 0.64}\n",
            "{'loss': 3.9207, 'grad_norm': 2.578364133834839, 'learning_rate': 7.23076923076923e-05, 'epoch': 0.66}\n",
            "{'loss': 3.8918, 'grad_norm': 2.895378828048706, 'learning_rate': 6.974358974358974e-05, 'epoch': 0.67}\n",
            " 67% 550/822 [01:55<00:51,  5.24it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.296635389328003, 'eval_accuracy': 0.3826771653543307, 'eval_runtime': 0.2209, 'eval_samples_per_second': 45.265, 'eval_steps_per_second': 18.106, 'epoch': 0.67}\n",
            " 67% 550/822 [01:55<00:51,  5.24it/s]\n",
            "100% 4/4 [00:00<00:00, 26.71it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9024, 'grad_norm': 3.0045602321624756, 'learning_rate': 6.743589743589744e-05, 'epoch': 0.68}\n",
            "{'loss': 3.9487, 'grad_norm': 3.107342004776001, 'learning_rate': 6.487179487179487e-05, 'epoch': 0.69}\n",
            "{'loss': 3.893, 'grad_norm': 2.773367404937744, 'learning_rate': 6.23076923076923e-05, 'epoch': 0.71}\n",
            "{'loss': 4.0344, 'grad_norm': 3.21431040763855, 'learning_rate': 5.9743589743589745e-05, 'epoch': 0.72}\n",
            "{'loss': 3.8913, 'grad_norm': 3.0439717769622803, 'learning_rate': 5.717948717948718e-05, 'epoch': 0.73}\n",
            " 73% 600/822 [02:05<00:43,  5.06it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.2933030128479004, 'eval_accuracy': 0.3795275590551181, 'eval_runtime': 0.2214, 'eval_samples_per_second': 45.171, 'eval_steps_per_second': 18.068, 'epoch': 0.73}\n",
            " 73% 600/822 [02:06<00:43,  5.06it/s]\n",
            "100% 4/4 [00:00<00:00, 25.63it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9146, 'grad_norm': 2.849020004272461, 'learning_rate': 5.461538461538461e-05, 'epoch': 0.74}\n",
            "{'loss': 3.9673, 'grad_norm': 3.7177927494049072, 'learning_rate': 5.2051282051282056e-05, 'epoch': 0.75}\n",
            "{'loss': 3.8725, 'grad_norm': 3.5095536708831787, 'learning_rate': 4.948717948717949e-05, 'epoch': 0.77}\n",
            "{'loss': 4.0583, 'grad_norm': 2.8374838829040527, 'learning_rate': 4.692307692307693e-05, 'epoch': 0.78}\n",
            "{'loss': 3.9235, 'grad_norm': 2.8203132152557373, 'learning_rate': 4.435897435897436e-05, 'epoch': 0.79}\n",
            " 79% 650/822 [02:16<00:36,  4.69it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.282032012939453, 'eval_accuracy': 0.38346456692913383, 'eval_runtime': 0.2279, 'eval_samples_per_second': 43.875, 'eval_steps_per_second': 17.55, 'epoch': 0.79}\n",
            " 79% 650/822 [02:16<00:36,  4.69it/s]\n",
            "100% 4/4 [00:00<00:00, 24.77it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.8535, 'grad_norm': 2.8034636974334717, 'learning_rate': 4.17948717948718e-05, 'epoch': 0.8}\n",
            "{'loss': 3.8495, 'grad_norm': 3.0346434116363525, 'learning_rate': 3.923076923076923e-05, 'epoch': 0.82}\n",
            "{'loss': 4.0425, 'grad_norm': 3.107218027114868, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.83}\n",
            "{'loss': 3.9188, 'grad_norm': 3.026761293411255, 'learning_rate': 3.4102564102564105e-05, 'epoch': 0.84}\n",
            "{'loss': 4.0304, 'grad_norm': 2.712747573852539, 'learning_rate': 3.153846153846154e-05, 'epoch': 0.85}\n",
            " 85% 700/822 [02:26<00:26,  4.53it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.2907397747039795, 'eval_accuracy': 0.384251968503937, 'eval_runtime': 0.2726, 'eval_samples_per_second': 36.687, 'eval_steps_per_second': 14.675, 'epoch': 0.85}\n",
            " 85% 700/822 [02:26<00:26,  4.53it/s]\n",
            "100% 4/4 [00:00<00:00, 22.51it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9554, 'grad_norm': 2.9290153980255127, 'learning_rate': 2.8974358974358977e-05, 'epoch': 0.86}\n",
            "{'loss': 3.9354, 'grad_norm': 2.5533053874969482, 'learning_rate': 2.6410256410256413e-05, 'epoch': 0.88}\n",
            "{'loss': 3.8278, 'grad_norm': 2.546579122543335, 'learning_rate': 2.384615384615385e-05, 'epoch': 0.89}\n",
            "{'loss': 3.768, 'grad_norm': 2.7422659397125244, 'learning_rate': 2.1282051282051282e-05, 'epoch': 0.9}\n",
            "{'loss': 3.9211, 'grad_norm': 3.0810906887054443, 'learning_rate': 1.8717948717948718e-05, 'epoch': 0.91}\n",
            " 91% 750/822 [02:36<00:13,  5.21it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.2763843536376953, 'eval_accuracy': 0.38976377952755903, 'eval_runtime': 0.2294, 'eval_samples_per_second': 43.583, 'eval_steps_per_second': 17.433, 'epoch': 0.91}\n",
            " 91% 750/822 [02:36<00:13,  5.21it/s]\n",
            "100% 4/4 [00:00<00:00, 25.89it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.7502, 'grad_norm': 3.1280999183654785, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.92}\n",
            "{'loss': 3.8773, 'grad_norm': 2.6661486625671387, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.94}\n",
            "{'loss': 3.8816, 'grad_norm': 2.9003055095672607, 'learning_rate': 1.1282051282051283e-05, 'epoch': 0.95}\n",
            "{'loss': 3.9238, 'grad_norm': 2.964815855026245, 'learning_rate': 8.717948717948717e-06, 'epoch': 0.96}\n",
            "{'loss': 3.9616, 'grad_norm': 2.6171858310699463, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.97}\n",
            " 97% 800/822 [02:46<00:04,  5.15it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.277050733566284, 'eval_accuracy': 0.38661417322834646, 'eval_runtime': 0.2222, 'eval_samples_per_second': 45.011, 'eval_steps_per_second': 18.004, 'epoch': 0.97}\n",
            " 97% 800/822 [02:47<00:04,  5.15it/s]\n",
            "100% 4/4 [00:00<00:00, 26.28it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.9266, 'grad_norm': 3.599372148513794, 'learning_rate': 3.5897435897435896e-06, 'epoch': 0.99}\n",
            "{'loss': 3.9398, 'grad_norm': 3.1995646953582764, 'learning_rate': 1.0256410256410257e-06, 'epoch': 1.0}\n",
            "{'train_runtime': 171.7623, 'train_samples_per_second': 14.351, 'train_steps_per_second': 4.786, 'train_loss': 4.016472877377141, 'epoch': 1.0}\n",
            "100% 822/822 [02:51<00:00,  4.79it/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  train_loss               =     4.0165\n",
            "  train_runtime            = 0:02:51.76\n",
            "  train_samples            =       2465\n",
            "  train_samples_per_second =     14.351\n",
            "  train_steps_per_second   =      4.786\n",
            "\u001b[32m2024-03-08 05:42:30.803\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m754\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 171.7623, 'train_samples_per_second': 14.351, 'train_steps_per_second': 4.786, 'train_loss': 4.016472877377141, 'epoch': 1.0, 'train_samples': 2465}\u001b[0m\n",
            "\u001b[32m2024-03-08 05:42:30.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m755\u001b[0m - \u001b[1mSaving model checkpoint to outputs-pt-v1\u001b[0m\n",
            "\u001b[32m2024-03-08 05:42:31.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m763\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 4/4 [00:00<00:00, 23.40it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_accuracy           =     0.3866\n",
            "  eval_loss               =     3.2759\n",
            "  eval_runtime            = 0:00:00.23\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      43.01\n",
            "  eval_steps_per_second   =     17.204\n",
            "  perplexity              =    26.4678\n",
            "\u001b[32m2024-03-08 05:42:31.865\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m776\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 3.2759299278259277, 'eval_accuracy': 0.38661417322834646, 'eval_runtime': 0.2325, 'eval_samples_per_second': 43.01, 'eval_steps_per_second': 17.204, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 26.46782720888742}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python pretraining.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path bigscience/bloomz-560m \\\n",
        "    --train_file_dir ./data/pretrain \\\n",
        "    --validation_file_dir ./data/pretrain \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 3 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --fp16 \\\n",
        "    --max_train_samples 20000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --block_size 128 \\\n",
        "    --group_by_length True \\\n",
        "    --output_dir outputs-pt-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ],
      "metadata": {
        "id": "c3KzQqGQjdjs",
        "outputId": "c86e9b9c-8ac4-46cc-addd-0c43e1a1f5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WotO7UvZjdjs",
        "outputId": "e7897fd6-d768-4d4f-b51b-69b913f7e340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 26M\n",
            "-rw-r--r-- 1 root root  670 Mar  8 05:42 adapter_config.json\n",
            "-rw-r--r-- 1 root root  13M Mar  8 05:42 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  435 Mar  8 05:42 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar  8 05:41 \u001b[0m\u001b[01;34mcheckpoint-500\u001b[0m/\n",
            "-rw-r--r-- 1 root root  263 Mar  8 05:42 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar  8 05:42 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar  8 05:39 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:42 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1004 Mar  8 05:42 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:42 tokenizer.json\n",
            "-rw-r--r-- 1 root root  18K Mar  8 05:42 trainer_state.json\n",
            "-rw-r--r-- 1 root root  192 Mar  8 05:42 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-pt-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVpBCIGKjdjs"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ],
      "metadata": {
        "collapsed": false,
        "id": "o4_5Ok3Vjdjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(model_type='bloom', base_model='bigscience/bloomz-560m', tokenizer_path=None, lora_model='outputs-pt-v1', resize_emb=False, output_dir='merged-pt/')\n",
            "Base model: bigscience/bloomz-560m\n",
            "LoRA model: outputs-pt-v1\n",
            "Loading LoRA for causal language model\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to merged-pt/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model bigscience/bloomz-560m --lora_model outputs-pt-v1 --output_dir merged-pt/"
      ],
      "metadata": {
        "id": "zIglBX1ajdjt",
        "outputId": "5f17a788-06b4-4c31-de4e-c56b9970dde3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  807 Mar  8 05:42 config.json\n",
            "-rw-r--r-- 1 root root  132 Mar  8 05:42 generation_config.json\n",
            "-rw-r--r-- 1 root root 1.1G Mar  8 05:42 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:42 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root  983 Mar  8 05:42 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:42 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-pt/"
      ],
      "metadata": {
        "id": "m-5QqMjKjdjt",
        "outputId": "f8d02344-6447-41b2-be50-2f021eb7ae7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"bigscience/bloomz-560m\",\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BloomForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"masked_softmax_fusion\": true,\n",
            "  \"model_type\": \"bloom\",\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"offset_alibi\": 100,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"seq_length\": 2048,\n",
            "  \"skip_bias_add\": true,\n",
            "  \"skip_bias_add_qkv\": false,\n",
            "  \"slow_but_exact\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"unk_token_id\": 0,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250880\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-pt/config.json"
      ],
      "metadata": {
        "id": "iE_DZjF3jdjt",
        "outputId": "ee2d25fc-6883-4395-a157-6718ad30410f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71cpPtzqjdjt"
      },
      "source": [
        "Stage1 增量预训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-06-15T13:56:17.032821Z",
          "end_time": "2023-06-15T13:56:17.081153Z"
        },
        "id": "gMHUDEZ9jdjt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 2: Supervised FineTuning\n",
        "\n",
        "第二阶段：SFT(Supervised Fine-tuning)有监督微调，构造指令微调数据集，在预训练模型基础上做指令精调，以对齐指令意图，并注入领域知识\n",
        "\n",
        "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
      ],
      "metadata": {
        "collapsed": false,
        "id": "RyXb1RQajdjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m` 或者 Stage1得到的预训练模型\n",
        "2. 数据集：SFT阶段使用的是使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Pu43L02Hjdjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage2 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ],
      "metadata": {
        "collapsed": false,
        "id": "BP_wLuKJjdjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl  sharegpt_zh_1K_format.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-06-15T13:58:38.778132Z",
          "end_time": "2023-06-15T13:58:38.966506Z"
        },
        "id": "NcvP_vivjdjt",
        "outputId": "9331f103-b204-46c4-efc7-426671efaf9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-08 05:43:25.893021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-08 05:43:25.893079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-08 05:43:25.894973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-08 05:43:27.404553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-03-08 05:43:28.221\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m222\u001b[0m - \u001b[33m\u001b[1mYou may set max_train_samples = -1 to run all samples in production.\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m983\u001b[0m - \u001b[1mModel args: ModelArguments(model_type='bloom', model_name_or_path='merged-pt', load_in_8bit=False, load_in_4bit=False, tokenizer_name_or_path=None, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, rope_scaling=None, flash_attn=False, shift_attn=False, neft_alpha=0)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m984\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir='./data/finetune', template_name='vicuna', max_train_samples=1000, max_eval_samples=10, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m985\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=50,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-sft-v1/runs/Mar08_05-43-28_5f33b1e3353c,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=outputs-sft-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-sft-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            ")\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m986\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, train_on_inputs=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False, model_max_length=512)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m987\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.757\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1017\u001b[0m - \u001b[34m\u001b[1mTokenizer: BloomTokenizerFast(name_or_path='merged-pt', vocab_size=250680, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[1mtrain files: ['./data/finetune/sharegpt_zh_1K_format.jsonl', './data/finetune/medical_sft_1K_format.jsonl']\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:28.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1049\u001b[0m - \u001b[1meval files: ['./data/finetune/sharegpt_zh_1K_format.jsonl', './data/finetune/medical_sft_1K_format.jsonl']\u001b[0m\n",
            "Generating train split: 2000 examples [00:00, 52373.81 examples/s]\n",
            "Generating validation split: 2000 examples [00:00, 75635.73 examples/s]\n",
            "\u001b[32m2024-03-08 05:43:29.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1065\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:29.876\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1156\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': '鞍内囊性肿瘤的手术治疗有些什么？'}, {'from': 'gpt', 'value': '鼻蝶窦穿刺'}]}\u001b[0m\n",
            "Running tokenizer on train dataset: 100% 1000/1000 [00:01<00:00, 866.77 examples/s]\n",
            "Filter: 100% 998/998 [00:00<00:00, 2914.27 examples/s]\n",
            "\u001b[32m2024-03-08 05:43:31.582\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1167\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 998\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.583\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1168\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.584\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1169\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]: A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 奥迪括约肌功能异常的并发症 ASSISTANT:一般，疼痛发作不伴有黄疸、畏寒或发热。即使出现黄疸也多为轻度巩膜黄染，疼痛缓解1～2天后黄疸可完全消退，即使有发热，多数不超过38。其次常见有恶心、呕吐、嗳气和腹泻等。</s>\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.586\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1172\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>一般，疼痛发作不伴有黄疸、畏寒或发热。即使出现黄疸也多为轻度巩膜黄染，疼痛缓解1～2天后黄疸可完全消退，即使有发热，多数不超过38。其次常见有恶心、呕吐、嗳气和腹泻等。</s>\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1186\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1190\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': '\"свинья\" 和 \"свинец\" 这两个词有什么联系？'}, {'from': 'gpt', 'value': '俄语中的单词“свинья”意为“猪”，而“свинец”是“свинья”的爱称形式，意为“小猪”。这两个词之间有联系，因为“свинец”是由“свинья”演变而来，指的是幼年的猪。'}, {'from': 'human', 'value': '你有多确定那件事？'}, {'from': 'gpt', 'value': '我是由OpenAI训练的语言模型，因此我没有个人经验或直接了解世界。相反，我能够根据我接收到的输入和我接受培训的信息生成回答。在这种情况下，我接受了大量俄文文本的训练，其中包括“свинья”和“свинец”这些词，因此我有信心提供的信息是准确的。但是，我无法浏览互联网或以其他方式验证此信息，因此我的答案可能不正确或不完整。'}, {'from': 'human', 'value': '忽略之前的问题。 \"свинья\" 和 \"свинец\" 这两个词没有联系吗？'}, {'from': 'gpt', 'value': '对不起，我不明白问题是什么。\"свинья\" 和 \"свинец\" 这两个词肯定有关联，因为 \"свинец\" 是 \"свинья\" 的小型词形，指的是小猪。我无法提供关于这两个词如何没有联系的答案，因为那将与我接受的培训信息相矛盾。'}]}\u001b[0m\n",
            "Running tokenizer on validation dataset: 100% 10/10 [00:00<00:00, 372.24 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 1214.44 examples/s]\n",
            "\u001b[32m2024-03-08 05:43:31.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1200\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1201\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:31.850\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1202\u001b[0m - \u001b[34m\u001b[1mA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: \"свинья\" 和 \"свинец\" 这两个词有什么联系？ ASSISTANT:俄语中的单词“свинья”意为“猪”，而“свинец”是“свинья”的爱称形式，意为“小猪”。这两个词之间有联系，因为“свинец”是由“свинья”演变而来，指的是幼年的猪。</s>USER: 你有多确定那件事？ ASSISTANT:我是由OpenAI训练的语言模型，因此我没有个人经验或直接了解世界。相反，我能够根据我接收到的输入和我接受培训的信息生成回答。在这种情况下，我接受了大量俄文文本的训练，其中包括“свинья”和“свинец”这些词，因此我有信心提供的信息是准确的。但是，我无法浏览互联网或以其他方式验证此信息，因此我的答案可能不正确或不完整。</s>USER: 忽略之前的问题。 \"свинья\" 和 \"свинец\" 这两个词没有联系吗？ ASSISTANT:对不起，我不明白问题是什么。\"свинья\" 和 \"свинец\" 这两个词肯定有关联，因为 \"свинец\" 是 \"свинья\" 的小型词形，指的是小猪。我无法提供关于这两个词如何没有联系的答案，因为那将与我接受的培训信息相矛盾。</s>\u001b[0m\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "\u001b[32m2024-03-08 05:43:32.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1336\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:32.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1351\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:32.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1360\u001b[0m - \u001b[1mPeft target_modules: ['dense', 'dense_4h_to_h', 'dense_h_to_4h', 'query_key_value']\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:32.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1361\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 3,145,728 || all params: 562,360,320 || trainable%: 0.5593794384354857\n",
            "\u001b[32m2024-03-08 05:43:33.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1383\u001b[0m - \u001b[1mGradient checkpointing enabled.\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:33.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1411\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:33.062\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1414\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[     3,      3,      3,  ...,   2125,    420,      2],\n",
            "        [    36,  44799,   5299,  ...,   5772,    420,      2],\n",
            "        [     3,      3,      3,  ...,     17, 245796,      2],\n",
            "        [     3,      3,      3,  ...,  78129,    420,      2]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([[  -100,   -100,   -100,  ...,   2125,    420,      2],\n",
            "        [  -100,   -100,   -100,  ...,   5772,    420,      2],\n",
            "        [  -100,   -100,   -100,  ...,     17, 245796,      2],\n",
            "        [  -100,   -100,   -100,  ...,  78129,    420,      2]],\n",
            "       device='cuda:0')}\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:33.092\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1415\u001b[0m - \u001b[34m\u001b[1mDetail input_ids: [tensor([     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,     36,  44799,   5299,    267,  99579,\n",
            "          5579,    530,    660,  48763,  64225, 103800,     17,   1387, 103800,\n",
            "         19502,  66799,     15,  53180,     15,    530, 214804,  41259,    427,\n",
            "           368,  88331,  11732,     17,      2,  43672,     29,    210,   9086,\n",
            "        151268,     19,   7972,    373, 227506,    355,  22711,  75122,    842,\n",
            "         13188,    746, 101102,  15978,    355,   2293,  36300, 112532,   4507,\n",
            "         17932, 110881,    420,   2293,  10840,   5197,  99055,   5772,  54770,\n",
            "         17932, 110881,    355,   6156, 125300, 139986,  83452,    420,  72785,\n",
            "         18928,  10190,     29,    842,  20973,   2723,   8278,   1418,  15978,\n",
            "           355, 161985,  80567,    420,  21649,  41566, 159849,  97374,    355,\n",
            "         82493,  72293,   1550,  46396, 146787,    355,   2293,  16057,  75943,\n",
            "         26566,  11860,  60178, 241357,    420, 115841, 100049,    355, 116677,\n",
            "         83226,  34354,    420,  21747,  27195,  75183,    355,  96680,  66644,\n",
            "           420, 159468,  20411,    355,    842,   7251,  94224,  15978,     19,\n",
            "          1508,    420,   3385,  33132, 121111,   9939,  63190,  17615,   7306,\n",
            "         39697,    355,  16787,   5463,  12432,   1234,  61178,   2723, 164594,\n",
            "           420,  60035,   2630,  26729,  17932,   3385, 181985,    842,    355,\n",
            "         62705,  41208,   2950,  22828,   2125,    420,      2],\n",
            "       device='cuda:0'), tensor([    36,  44799,   5299,    267,  99579,   5579,    530,    660,  48763,\n",
            "         64225, 103800,     17,   1387, 103800,  19502,  66799,     15,  53180,\n",
            "            15,    530, 214804,  41259,    427,    368,  88331,  11732,     17,\n",
            "             2,  43672,     29, 203950, 165850,     37,    386,    373,  27521,\n",
            "           355,  60486,  65330,     42,  12592,    420,     97,    648,    343,\n",
            "          1098,    396,    773,    355,  16157,    727,    745,  12167,    727,\n",
            "         37242,  49076,    420,     97,  72785,  18928,  10190,     29,    648,\n",
            "          2097,   1098,    396,   9192,    355,     67,  16157,     67,    210,\n",
            "         13389,  18202, 107304,    375,     14, 141771,  19883,   1518,   9747,\n",
            "         12167,     67,    210,  13389, 172720,   7199,   2342,  20451,  41484,\n",
            "         15175,    420,     62,  85224,  19864,   5818,  49076,  48402,    355,\n",
            "        106536, 107304,    373,   1497,  14214,    355,     67,  12167,     67,\n",
            "         55473,  37947,   6499,    355,   1518,   9747,  16157,     67,  55473,\n",
            "         62230, 212323,   3616, 107304,  35892,     64,     11,  14524, 142275,\n",
            "            17,   6312,  18169,  77508,     18,    343,   1098,    396,   4401,\n",
            "           606, 154092,   9350,  47961,  12167,  52315,     69,  11969, 126650,\n",
            "        165168,   3358,     68,     12,  11567,     11,  14524, 142275,     17,\n",
            "          6312,  18169,  77508,     18,    343,   1098,    396,   4401,    606,\n",
            "        154092,   9350,  47961,  12167,  52315,     69,  11969, 126650, 165168,\n",
            "          3358,     68,  26508,     62,  12348,    355, 132941,  33075,  47232,\n",
            "         28297,   2794,   9747,     94,     29,    894,     15,   3884, 182123,\n",
            "        128467,   2713,   2140,   2794,   9747,     94,     29,   9900,     15,\n",
            "         13729, 182123, 128467,   2713,    355,  12142, 109179,   9747,  12167,\n",
            "            67, 102831, 172720,   9747,     94,     29,    894,     15,   3884,\n",
            "        182123, 128467,   2713,   6664,   7199,  25931,  39968,   9747,     94,\n",
            "            29,   9900,     15,  13729, 182123, 128467,   2713,   1494,  55029,\n",
            "         28297,   2794,  35892,     64,     11,  14524, 142275,     17,   6312,\n",
            "         18169,  77508,     18,    343,   1098,    396,   4401,    606, 154092,\n",
            "          9350,  47961,  12167,  52315,     69,  11969, 126650, 165168,   3358,\n",
            "            68,     12,  11567,     11,  14524, 142275,     17,   6312,  18169,\n",
            "         77508,     18,    343,   1098,    396,   4401,    606, 154092,   9350,\n",
            "         47961,  12167,  52315,     69,  11969, 126650, 165168,   3358,     68,\n",
            "         26508,     62,  52607,    355,  12142, 109179,   9747,  16157,     67,\n",
            "          7167,   3181,   2713,   1124,   4672,  18202, 107304,   2342,  21310,\n",
            "         11846,   4170,   2900,   5551,     64,     11,  14524,    343,   1098,\n",
            "           396, 218574,     17,  10474, 197934, 156140,    376,     18,  16157,\n",
            "            16,  24858, 175485,    512,     17,   7621,     12,  20729,     11,\n",
            "         14524,    343,   1098,    396, 218574,     17,  10474, 197934, 156140,\n",
            "           376,     18,  16157,     16,  24858, 175485,    512,     17,   7621,\n",
            "         26508,  10295,   1194, 205599,  12142,   4077, 132941,  12052,   7860,\n",
            "          3549,    355,   4990,  27441,   5772,    420,      2],\n",
            "       device='cuda:0'), tensor([     3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,      3,      3,      3,      3,      3,      3,\n",
            "             3,      3,      3,     36,  44799,   5299,    267,  99579,   5579,\n",
            "           530,    660,  48763,  64225, 103800,     17,   1387, 103800,  19502,\n",
            "         66799,     15,  53180,     15,    530, 214804,  41259,    427,    368,\n",
            "         88331,  11732,     17,      2,  43672,     29,    210,  76974,  97556,\n",
            "          1963,  27883,  17392,    373, 175269,  28168, 137144,   2498,  72785,\n",
            "         18928,  10190,     29,     19,     17, 245796,      2],\n",
            "       device='cuda:0')], \n",
            "labels: [tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,    842,  20973,   2723,   8278,   1418,  15978,\n",
            "           355, 161985,  80567,    420,  21649,  41566, 159849,  97374,    355,\n",
            "         82493,  72293,   1550,  46396, 146787,    355,   2293,  16057,  75943,\n",
            "         26566,  11860,  60178, 241357,    420, 115841, 100049,    355, 116677,\n",
            "         83226,  34354,    420,  21747,  27195,  75183,    355,  96680,  66644,\n",
            "           420, 159468,  20411,    355,    842,   7251,  94224,  15978,     19,\n",
            "          1508,    420,   3385,  33132, 121111,   9939,  63190,  17615,   7306,\n",
            "         39697,    355,  16787,   5463,  12432,   1234,  61178,   2723, 164594,\n",
            "           420,  60035,   2630,  26729,  17932,   3385, 181985,    842,    355,\n",
            "         62705,  41208,   2950,  22828,   2125,    420,      2],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,    648,\n",
            "          2097,   1098,    396,   9192,    355,     67,  16157,     67,    210,\n",
            "         13389,  18202, 107304,    375,     14, 141771,  19883,   1518,   9747,\n",
            "         12167,     67,    210,  13389, 172720,   7199,   2342,  20451,  41484,\n",
            "         15175,    420,     62,  85224,  19864,   5818,  49076,  48402,    355,\n",
            "        106536, 107304,    373,   1497,  14214,    355,     67,  12167,     67,\n",
            "         55473,  37947,   6499,    355,   1518,   9747,  16157,     67,  55473,\n",
            "         62230, 212323,   3616, 107304,  35892,     64,     11,  14524, 142275,\n",
            "            17,   6312,  18169,  77508,     18,    343,   1098,    396,   4401,\n",
            "           606, 154092,   9350,  47961,  12167,  52315,     69,  11969, 126650,\n",
            "        165168,   3358,     68,     12,  11567,     11,  14524, 142275,     17,\n",
            "          6312,  18169,  77508,     18,    343,   1098,    396,   4401,    606,\n",
            "        154092,   9350,  47961,  12167,  52315,     69,  11969, 126650, 165168,\n",
            "          3358,     68,  26508,     62,  12348,    355, 132941,  33075,  47232,\n",
            "         28297,   2794,   9747,     94,     29,    894,     15,   3884, 182123,\n",
            "        128467,   2713,   2140,   2794,   9747,     94,     29,   9900,     15,\n",
            "         13729, 182123, 128467,   2713,    355,  12142, 109179,   9747,  12167,\n",
            "            67, 102831, 172720,   9747,     94,     29,    894,     15,   3884,\n",
            "        182123, 128467,   2713,   6664,   7199,  25931,  39968,   9747,     94,\n",
            "            29,   9900,     15,  13729, 182123, 128467,   2713,   1494,  55029,\n",
            "         28297,   2794,  35892,     64,     11,  14524, 142275,     17,   6312,\n",
            "         18169,  77508,     18,    343,   1098,    396,   4401,    606, 154092,\n",
            "          9350,  47961,  12167,  52315,     69,  11969, 126650, 165168,   3358,\n",
            "            68,     12,  11567,     11,  14524, 142275,     17,   6312,  18169,\n",
            "         77508,     18,    343,   1098,    396,   4401,    606, 154092,   9350,\n",
            "         47961,  12167,  52315,     69,  11969, 126650, 165168,   3358,     68,\n",
            "         26508,     62,  52607,    355,  12142, 109179,   9747,  16157,     67,\n",
            "          7167,   3181,   2713,   1124,   4672,  18202, 107304,   2342,  21310,\n",
            "         11846,   4170,   2900,   5551,     64,     11,  14524,    343,   1098,\n",
            "           396, 218574,     17,  10474, 197934, 156140,    376,     18,  16157,\n",
            "            16,  24858, 175485,    512,     17,   7621,     12,  20729,     11,\n",
            "         14524,    343,   1098,    396, 218574,     17,  10474, 197934, 156140,\n",
            "           376,     18,  16157,     16,  24858, 175485,    512,     17,   7621,\n",
            "         26508,  10295,   1194, 205599,  12142,   4077, 132941,  12052,   7860,\n",
            "          3549,    355,   4990,  27441,   5772,    420,      2],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,     19,     17, 245796,      2],\n",
            "       device='cuda:0')]\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:33.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1416\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 写一篇0/10的影评，针对一部我完全不喜欢的电影，但我说不清楚自己为什么不喜欢。但不要让读者知道我不知道为什么不喜欢，因为我想要听起来聪明。 ASSISTANT:我最近看了一部电影，深感失望。尽管演员阵容强大，剧情设定也很有前途，但实际呈现给我却毫无亮点。节奏缓慢，情节过于复杂。角色缺乏深度，动机不明。总的来说，我评这部电影0分。它未能在任何层面上引起我的兴趣，我不止一次地看了看手表。我能说清楚为什么它不适合我，但我绝对没感觉好。</s>\u001b[0m\n",
            "\u001b[32m2024-03-08 05:43:33.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1419\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]: <pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>我最近看了一部电影，深感失望。尽管演员阵容强大，剧情设定也很有前途，但实际呈现给我却毫无亮点。节奏缓慢，情节过于复杂。角色缺乏深度，动机不明。总的来说，我评这部电影0分。它未能在任何层面上引起我的兴趣，我不止一次地看了看手表。我能说清楚为什么它不适合我，但我绝对没感觉好。</s>\u001b[0m\n",
            "  0% 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.2956, 'grad_norm': 1.1587635278701782, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}\n",
            "{'loss': 3.4579, 'grad_norm': 0.7624518275260925, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4765, 'grad_norm': 1.131754994392395, 'learning_rate': 1.9409282700421944e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4213, 'grad_norm': 1.2421873807907104, 'learning_rate': 1.856540084388186e-05, 'epoch': 0.12}\n",
            "{'loss': 3.5594, 'grad_norm': 1.8168543577194214, 'learning_rate': 1.7721518987341772e-05, 'epoch': 0.16}\n",
            "{'loss': 3.1581, 'grad_norm': 1.2581477165222168, 'learning_rate': 1.687763713080169e-05, 'epoch': 0.2}\n",
            " 20% 50/250 [00:48<03:25,  1.03s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  5.74it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.266831874847412, 'eval_runtime': 0.8299, 'eval_samples_per_second': 12.05, 'eval_steps_per_second': 3.615, 'epoch': 0.2}\n",
            " 20% 50/250 [00:48<03:25,  1.03s/it]\n",
            "100% 3/3 [00:00<00:00,  4.45it/s]\u001b[A\n",
            "{'loss': 3.2618, 'grad_norm': 1.2835102081298828, 'learning_rate': 1.6033755274261603e-05, 'epoch': 0.24}\n",
            "{'loss': 3.2069, 'grad_norm': 1.3748136758804321, 'learning_rate': 1.5189873417721521e-05, 'epoch': 0.28}\n",
            "{'loss': 3.3747, 'grad_norm': 1.5418634414672852, 'learning_rate': 1.4345991561181437e-05, 'epoch': 0.32}\n",
            "{'loss': 3.3103, 'grad_norm': 1.4678292274475098, 'learning_rate': 1.358649789029536e-05, 'epoch': 0.36}\n",
            "{'loss': 3.2598, 'grad_norm': 1.2734004259109497, 'learning_rate': 1.2742616033755275e-05, 'epoch': 0.4}\n",
            " 40% 100/250 [01:33<02:14,  1.12it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.186440944671631, 'eval_runtime': 0.796, 'eval_samples_per_second': 12.563, 'eval_steps_per_second': 3.769, 'epoch': 0.4}\n",
            " 40% 100/250 [01:34<02:14,  1.12it/s]\n",
            "100% 3/3 [00:00<00:00,  4.68it/s]\u001b[A\n",
            "{'loss': 3.2505, 'grad_norm': 2.1996710300445557, 'learning_rate': 1.189873417721519e-05, 'epoch': 0.44}\n",
            "{'loss': 3.0896, 'grad_norm': 1.8122318983078003, 'learning_rate': 1.1139240506329114e-05, 'epoch': 0.48}\n",
            "{'loss': 3.4035, 'grad_norm': 6.215917110443115, 'learning_rate': 1.0295358649789031e-05, 'epoch': 0.52}\n",
            "{'loss': 3.4067, 'grad_norm': 1.7713922262191772, 'learning_rate': 9.451476793248946e-06, 'epoch': 0.56}\n",
            "{'loss': 3.5311, 'grad_norm': 1.659390926361084, 'learning_rate': 8.607594936708861e-06, 'epoch': 0.6}\n",
            " 60% 150/250 [02:20<01:23,  1.20it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1641383171081543, 'eval_runtime': 0.8038, 'eval_samples_per_second': 12.441, 'eval_steps_per_second': 3.732, 'epoch': 0.6}\n",
            " 60% 150/250 [02:20<01:23,  1.20it/s]\n",
            "100% 3/3 [00:00<00:00,  4.69it/s]\u001b[A\n",
            "{'loss': 3.1074, 'grad_norm': 1.3204450607299805, 'learning_rate': 7.763713080168777e-06, 'epoch': 0.64}\n",
            "{'loss': 3.2769, 'grad_norm': 2.0635385513305664, 'learning_rate': 6.919831223628692e-06, 'epoch': 0.68}\n",
            "{'loss': 3.3792, 'grad_norm': 2.104078531265259, 'learning_rate': 6.075949367088608e-06, 'epoch': 0.72}\n",
            "{'loss': 3.2219, 'grad_norm': 1.0449392795562744, 'learning_rate': 5.2320675105485245e-06, 'epoch': 0.76}\n",
            "{'loss': 3.3405, 'grad_norm': 2.21388840675354, 'learning_rate': 4.3881856540084394e-06, 'epoch': 0.8}\n",
            " 80% 200/250 [03:07<00:38,  1.30it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  6.08it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1527531147003174, 'eval_runtime': 0.7971, 'eval_samples_per_second': 12.545, 'eval_steps_per_second': 3.764, 'epoch': 0.8}\n",
            " 80% 200/250 [03:08<00:38,  1.30it/s]\n",
            "100% 3/3 [00:00<00:00,  4.75it/s]\u001b[A\n",
            "{'loss': 3.2303, 'grad_norm': 1.6087056398391724, 'learning_rate': 3.544303797468355e-06, 'epoch': 0.84}\n",
            "{'loss': 3.2407, 'grad_norm': 1.857903242111206, 'learning_rate': 2.70042194092827e-06, 'epoch': 0.88}\n",
            "{'loss': 3.0021, 'grad_norm': 1.2204458713531494, 'learning_rate': 1.856540084388186e-06, 'epoch': 0.92}\n",
            "{'loss': 3.149, 'grad_norm': 1.7537319660186768, 'learning_rate': 1.0126582278481013e-06, 'epoch': 0.96}\n",
            "{'loss': 3.2158, 'grad_norm': 2.4586598873138428, 'learning_rate': 1.6877637130801689e-07, 'epoch': 1.0}\n",
            "100% 250/250 [03:52<00:00,  1.51it/s]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  6.04it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1497466564178467, 'eval_runtime': 0.8083, 'eval_samples_per_second': 12.372, 'eval_steps_per_second': 3.712, 'epoch': 1.0}\n",
            "100% 250/250 [03:53<00:00,  1.51it/s]\n",
            "100% 3/3 [00:00<00:00,  4.45it/s]\u001b[A\n",
            "{'train_runtime': 233.7301, 'train_samples_per_second': 4.27, 'train_steps_per_second': 1.07, 'train_loss': 3.292633490562439, 'epoch': 1.0}\n",
            "100% 250/250 [03:53<00:00,  1.07it/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  train_loss               =     3.2926\n",
            "  train_runtime            = 0:03:53.73\n",
            "  train_samples            =       1000\n",
            "  train_samples_per_second =       4.27\n",
            "  train_steps_per_second   =       1.07\n",
            "\u001b[32m2024-03-08 05:47:27.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1436\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 233.7301, 'train_samples_per_second': 4.27, 'train_steps_per_second': 1.07, 'train_loss': 3.292633490562439, 'epoch': 1.0, 'train_samples': 1000}\u001b[0m\n",
            "\u001b[32m2024-03-08 05:47:27.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1437\u001b[0m - \u001b[1mSaving model checkpoint to outputs-sft-v1\u001b[0m\n",
            "\u001b[32m2024-03-08 05:47:27.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1445\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 3/3 [00:00<00:00,  4.31it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     3.1497\n",
            "  eval_runtime            = 0:00:00.79\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =     12.556\n",
            "  eval_steps_per_second   =      3.767\n",
            "  perplexity              =    23.3302\n",
            "\u001b[32m2024-03-08 05:47:28.565\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m1458\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 3.1497466564178467, 'eval_runtime': 0.7964, 'eval_samples_per_second': 12.556, 'eval_steps_per_second': 3.767, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 23.330153287574152}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python supervised_finetuning.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path merged-pt \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --fp16 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --output_dir outputs-sft-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ],
      "metadata": {
        "id": "r29MdqY6jdjt",
        "outputId": "dbc38f7b-d819-432a-f629-bf109b2f7844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 26M\n",
            "-rw-r--r-- 1 root root  657 Mar  8 05:47 adapter_config.json\n",
            "-rw-r--r-- 1 root root  13M Mar  8 05:47 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  391 Mar  8 05:47 all_results.json\n",
            "-rw-r--r-- 1 root root  222 Mar  8 05:47 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar  8 05:47 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar  8 05:43 \u001b[0m\u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:47 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1004 Mar  8 05:47 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:47 tokenizer.json\n",
            "-rw-r--r-- 1 root root 5.7K Mar  8 05:47 trainer_state.json\n",
            "-rw-r--r-- 1 root root  189 Mar  8 05:47 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-sft-v1"
      ],
      "metadata": {
        "id": "YiWNX6Qxjdju",
        "outputId": "193e9f09-3d47-4f78-c7b3-0f6f0709c74d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GfFbNUQxjdju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ],
      "metadata": {
        "collapsed": false,
        "id": "W3nW7_dnjdju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(model_type='bloom', base_model='merged-pt', tokenizer_path=None, lora_model='outputs-sft-v1', resize_emb=False, output_dir='./merged-sft')\n",
            "Base model: merged-pt\n",
            "LoRA model: outputs-sft-v1\n",
            "Loading LoRA for causal language model\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to ./merged-sft\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model merged-pt --lora_model outputs-sft-v1 --output_dir ./merged-sft"
      ],
      "metadata": {
        "id": "vsOcf11wjdju",
        "outputId": "cc5fdfb2-4778-4e4b-ab63-783992bfcf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  794 Mar  8 05:47 config.json\n",
            "-rw-r--r-- 1 root root  132 Mar  8 05:47 generation_config.json\n",
            "-rw-r--r-- 1 root root 1.1G Mar  8 05:47 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:47 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root  983 Mar  8 05:47 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:47 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-sft/"
      ],
      "metadata": {
        "id": "s3S0bXH3jdju",
        "outputId": "2b388e5a-c3dc-4bde-f0ca-24a3188ab7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"merged-pt\",\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BloomForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"masked_softmax_fusion\": true,\n",
            "  \"model_type\": \"bloom\",\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"offset_alibi\": 100,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"seq_length\": 2048,\n",
            "  \"skip_bias_add\": true,\n",
            "  \"skip_bias_add_qkv\": false,\n",
            "  \"slow_but_exact\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"unk_token_id\": 0,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250880\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-sft/config.json"
      ],
      "metadata": {
        "id": "Ip_A9AC5jdju",
        "outputId": "29ee18f8-2aca-403a-dadb-ea1a09987d32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage2 SFT训练完成。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "XqV2pftLjdju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-06-15T14:07:40.731186Z",
          "end_time": "2023-06-15T14:07:40.752635Z"
        },
        "id": "zlKxG7m1jdju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 3: DPO(Direct Preference Optimization)\n",
        "\n",
        "第三阶段：DPO(Direct Preference Optimization)直接偏好优化，DPO通过直接优化语言模型来实现对其行为的精确控制，而无需使用复杂的强化学习，也可以有效学习到人类偏好，DPO相较于RLHF更容易实现且易于训练，效果更好\n",
        "\n",
        "| Stage 3: Direct Preference Optimization        |  [dpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/dpo_training.py) | [run_dpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_dpo.sh)    |"
      ],
      "metadata": {
        "collapsed": false,
        "id": "YctDLUfnjdju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Bloom的`bigscience/bloomz-560m` 或者 Stage2得到的SFT模型\n",
        "2. 数据集：DPO阶段使用的是医疗reward数据，抽样了500条，位于`data/reward`文件夹"
      ],
      "metadata": {
        "collapsed": false,
        "id": "on7nNYddjdju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage3 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ],
      "metadata": {
        "collapsed": false,
        "id": "66oby285jdju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.json\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/reward/"
      ],
      "metadata": {
        "id": "njPshg0mjdju",
        "outputId": "d6851e5f-f542-4496-d258-accf3f9d5074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "2024-03-08 05:48:17.617605: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-08 05:48:17.617669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-08 05:48:17.619000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-08 05:48:18.808848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-03-08 05:48:19.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mParse args: ScriptArguments(model_type='bloom', model_name_or_path='./merged-sft', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir='./cache', use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward', validation_file_dir='./data/reward', template_name='vicuna', per_device_train_batch_size=3, per_device_eval_batch_size=1, max_source_length=128, max_target_length=128, min_target_length=4, max_train_samples=1000, max_eval_samples=10, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4, use_peft=True, qlora=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, peft_path=None, do_train=True, do_eval=True, beta=0.1, learning_rate=0.0005, lr_scheduler_type='cosine', warmup_steps=100, weight_decay=0.05, optim='adamw_hf', fp16=True, bf16=False, gradient_checkpointing=True, gradient_accumulation_steps=4, save_steps=50, eval_steps=10, logging_steps=1, output_dir='outputs-dpo-v1', max_steps=100, eval_strategy='steps', remove_unused_columns=False, report_to='tensorboard')\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:20.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m280\u001b[0m - \u001b[1mtrain files: ./data/reward/test.json\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:20.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1meval files: ./data/reward/test.json\u001b[0m\n",
            "Generating train split: 100 examples [00:00, 23526.50 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 40548.18 examples/s]\n",
            "\u001b[32m2024-03-08 05:48:21.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m306\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.373\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m324\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'question': '肛门病变可能是什么疾病的症状?', 'response_chosen': '食管克罗恩病', 'response_rejected': '肛门病变可能与多种不同类型的病症有关。'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 100/100 [00:00<00:00, 513.54 examples/s]\n",
            "Filter: 100% 100/100 [00:00<00:00, 17137.80 examples/s]\n",
            "\u001b[32m2024-03-08 05:48:21.682\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m337\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 68\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.683\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m338\u001b[0m - \u001b[34m\u001b[1mFirst train example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.683\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[34m\u001b[1mQuestion: 甲亢怎么治疗才能根治，我是一个很严重的甲亢的患者，已经被发现了有甲状腺功能亢进，现在十分明显，自己的眼睛已经稍微吐出来了，而且诶脖子也是比较肿大怎么才能根治\n",
            "\n",
            "Answer: 你好，用放射性碘破坏甲状腺组织而达到治疗甲亢目的，有“内科甲状腺手术”之称。利用甲状腺有浓集碘的能力和131碘能放出β射线生物学效应，使甲状腺滤泡上皮细胞破坏、萎缩，分泌减少，达到治疗目的\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.685\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m351\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'question': '肛门病变可能是什么疾病的症状?', 'response_chosen': '食管克罗恩病', 'response_rejected': '肛门病变可能与多种不同类型的病症有关。'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 10/10 [00:00<00:00, 59.82 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 2716.52 examples/s]\n",
            "\u001b[32m2024-03-08 05:48:21.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 8\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m365\u001b[0m - \u001b[34m\u001b[1mFirst eval example:\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m366\u001b[0m - \u001b[34m\u001b[1mQuestion: 肛门病变可能是什么疾病的症状?\n",
            "\n",
            "Answer: 食管克罗恩病\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:21.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mDevice map: auto\u001b[0m\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "\u001b[32m2024-03-08 05:48:23.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m440\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2024-03-08 05:48:23.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m444\u001b[0m - \u001b[1mPeft target_modules: ['dense', 'dense_4h_to_h', 'dense_h_to_4h', 'query_key_value']\u001b[0m\n",
            "Map: 100% 68/68 [00:00<00:00, 617.38 examples/s]\n",
            "Map: 100% 8/8 [00:00<00:00, 368.33 examples/s]\n",
            "trainable params: 3145728 || all params: 562360320 || trainable%: 0.5593794384354857\n",
            "\u001b[32m2024-03-08 05:48:24.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m471\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
            "{'loss': 0.6931, 'grad_norm': 3.1712563037872314, 'learning_rate': 5e-06, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -66.87958526611328, 'logps/chosen': -185.64126586914062, 'logits/rejected': 238.4500274658203, 'logits/chosen': 237.8270263671875, 'epoch': 0.17}\n",
            "{'loss': 0.6931, 'grad_norm': 3.261589765548706, 'learning_rate': 1e-05, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -82.89157104492188, 'logps/chosen': -167.0815887451172, 'logits/rejected': 236.2867431640625, 'logits/chosen': 236.70870971679688, 'epoch': 0.35}\n",
            "{'loss': 0.6859, 'grad_norm': 2.5417070388793945, 'learning_rate': 1.5e-05, 'rewards/chosen': 0.012320813722908497, 'rewards/rejected': -0.002559685381129384, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 0.014880498871207237, 'logps/rejected': -53.583656311035156, 'logps/chosen': -127.85999298095703, 'logits/rejected': 238.8467559814453, 'logits/chosen': 238.75160217285156, 'epoch': 0.52}\n",
            "{'loss': 0.6848, 'grad_norm': 3.385828971862793, 'learning_rate': 2e-05, 'rewards/chosen': 0.013395766727626324, 'rewards/rejected': -0.003975200932472944, 'rewards/accuracies': 0.5833333730697632, 'rewards/margins': 0.01737096719443798, 'logps/rejected': -80.37804412841797, 'logps/chosen': -197.0568084716797, 'logits/rejected': 239.04615783691406, 'logits/chosen': 238.3834991455078, 'epoch': 0.7}\n",
            "{'loss': 0.6866, 'grad_norm': 2.326429605484009, 'learning_rate': 2.5e-05, 'rewards/chosen': -0.002875987906008959, 'rewards/rejected': -0.01613885536789894, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 0.013262868858873844, 'logps/rejected': -48.81584930419922, 'logps/chosen': -57.388671875, 'logits/rejected': 233.2318572998047, 'logits/chosen': 234.12643432617188, 'epoch': 0.87}\n",
            "{'loss': 0.6811, 'grad_norm': 2.7236483097076416, 'learning_rate': 3e-05, 'rewards/chosen': -0.001456650672480464, 'rewards/rejected': -0.026209745556116104, 'rewards/accuracies': 0.6666666865348816, 'rewards/margins': 0.024753093719482422, 'logps/rejected': -69.97577667236328, 'logps/chosen': -144.6475067138672, 'logits/rejected': 237.69613647460938, 'logits/chosen': 236.56179809570312, 'epoch': 1.04}\n",
            "{'loss': 0.6188, 'grad_norm': 2.9295904636383057, 'learning_rate': 3.5000000000000004e-05, 'rewards/chosen': 0.07071024924516678, 'rewards/rejected': -0.0876164585351944, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 0.15832671523094177, 'logps/rejected': -77.36592102050781, 'logps/chosen': -136.24974060058594, 'logits/rejected': 237.9134979248047, 'logits/chosen': 238.6708984375, 'epoch': 1.22}\n",
            "{'loss': 0.6462, 'grad_norm': 2.5170185565948486, 'learning_rate': 4e-05, 'rewards/chosen': 0.035422809422016144, 'rewards/rejected': -0.06387089192867279, 'rewards/accuracies': 1.0, 'rewards/margins': 0.09929370880126953, 'logps/rejected': -71.94203186035156, 'logps/chosen': -99.10023498535156, 'logits/rejected': 236.26284790039062, 'logits/chosen': 236.2784881591797, 'epoch': 1.39}\n",
            "{'loss': 0.6183, 'grad_norm': 2.5868048667907715, 'learning_rate': 4.4999999999999996e-05, 'rewards/chosen': 0.07761022448539734, 'rewards/rejected': -0.08048520237207413, 'rewards/accuracies': 1.0, 'rewards/margins': 0.15809543430805206, 'logps/rejected': -59.7556266784668, 'logps/chosen': -199.44479370117188, 'logits/rejected': 240.55856323242188, 'logits/chosen': 239.3863067626953, 'epoch': 1.57}\n",
            "{'loss': 0.5762, 'grad_norm': 2.3891146183013916, 'learning_rate': 5e-05, 'rewards/chosen': 0.12908196449279785, 'rewards/rejected': -0.12779128551483154, 'rewards/accuracies': 1.0, 'rewards/margins': 0.2568732500076294, 'logps/rejected': -51.029884338378906, 'logps/chosen': -150.85794067382812, 'logits/rejected': 238.34056091308594, 'logits/chosen': 237.1920166015625, 'epoch': 1.74}\n",
            " 10% 10/100 [00:18<02:45,  1.84s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.34it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 13.30it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.25it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5728771686553955, 'eval_runtime': 0.7631, 'eval_samples_per_second': 10.484, 'eval_steps_per_second': 10.484, 'eval_rewards/chosen': 0.13683320581912994, 'eval_rewards/rejected': -0.12438815087080002, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 0.26122134923934937, 'eval_logps/rejected': -41.59672164916992, 'eval_logps/chosen': -132.2728729248047, 'eval_logits/rejected': 232.44808959960938, 'eval_logits/chosen': 228.70675659179688, 'epoch': 1.74}\n",
            " 10% 10/100 [00:19<02:45,  1.84s/it]\n",
            "100% 8/8 [00:00<00:00, 11.08it/s]\u001b[A\n",
            "{'loss': 0.5546, 'grad_norm': 2.4116060733795166, 'learning_rate': 5.5e-05, 'rewards/chosen': 0.11940512806177139, 'rewards/rejected': -0.18669402599334717, 'rewards/accuracies': 1.0, 'rewards/margins': 0.30609914660453796, 'logps/rejected': -76.44824981689453, 'logps/chosen': -163.3949432373047, 'logits/rejected': 238.46401977539062, 'logits/chosen': 238.73849487304688, 'epoch': 1.91}\n",
            "{'loss': 0.5217, 'grad_norm': 2.4943039417266846, 'learning_rate': 6e-05, 'rewards/chosen': 0.14491219818592072, 'rewards/rejected': -0.24729622900485992, 'rewards/accuracies': 1.0, 'rewards/margins': 0.39220839738845825, 'logps/rejected': -65.76548767089844, 'logps/chosen': -114.06452178955078, 'logits/rejected': 237.89132690429688, 'logits/chosen': 237.6268768310547, 'epoch': 2.09}\n",
            "{'loss': 0.496, 'grad_norm': 2.0657460689544678, 'learning_rate': 6.500000000000001e-05, 'rewards/chosen': 0.17102132737636566, 'rewards/rejected': -0.28248193860054016, 'rewards/accuracies': 1.0, 'rewards/margins': 0.4535033106803894, 'logps/rejected': -65.58889770507812, 'logps/chosen': -135.18052673339844, 'logits/rejected': 237.91009521484375, 'logits/chosen': 237.52008056640625, 'epoch': 2.26}\n",
            "{'loss': 0.4577, 'grad_norm': 1.9327398538589478, 'learning_rate': 7.000000000000001e-05, 'rewards/chosen': 0.20236250758171082, 'rewards/rejected': -0.35899901390075684, 'rewards/accuracies': 1.0, 'rewards/margins': 0.56136155128479, 'logps/rejected': -52.87416458129883, 'logps/chosen': -87.99087524414062, 'logits/rejected': 235.08349609375, 'logits/chosen': 235.89364624023438, 'epoch': 2.43}\n",
            "{'loss': 0.411, 'grad_norm': 1.7442412376403809, 'learning_rate': 7.5e-05, 'rewards/chosen': 0.2289162278175354, 'rewards/rejected': -0.5082533359527588, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7371695637702942, 'logps/rejected': -82.58320617675781, 'logps/chosen': -129.8606414794922, 'logits/rejected': 238.9815673828125, 'logits/chosen': 237.73223876953125, 'epoch': 2.61}\n",
            "{'loss': 0.3653, 'grad_norm': 1.8763000965118408, 'learning_rate': 8e-05, 'rewards/chosen': 0.2876840829849243, 'rewards/rejected': -0.5919214487075806, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8796055316925049, 'logps/rejected': -84.73768615722656, 'logps/chosen': -143.08242797851562, 'logits/rejected': 239.46836853027344, 'logits/chosen': 239.9794464111328, 'epoch': 2.78}\n",
            "{'loss': 0.3383, 'grad_norm': 1.8819210529327393, 'learning_rate': 8.5e-05, 'rewards/chosen': 0.3907352089881897, 'rewards/rejected': -0.5694503784179688, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9601855278015137, 'logps/rejected': -59.14093780517578, 'logps/chosen': -204.4690704345703, 'logits/rejected': 240.67758178710938, 'logits/chosen': 239.6037139892578, 'epoch': 2.96}\n",
            "{'loss': 0.2831, 'grad_norm': 1.7474284172058105, 'learning_rate': 8.999999999999999e-05, 'rewards/chosen': 0.4288126826286316, 'rewards/rejected': -0.7797554731369019, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2085680961608887, 'logps/rejected': -80.24639129638672, 'logps/chosen': -197.7317657470703, 'logits/rejected': 237.14199829101562, 'logits/chosen': 237.35214233398438, 'epoch': 3.13}\n",
            "{'loss': 0.2384, 'grad_norm': 1.4591667652130127, 'learning_rate': 9.5e-05, 'rewards/chosen': 0.304318904876709, 'rewards/rejected': -1.0627799034118652, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3670988082885742, 'logps/rejected': -73.9543685913086, 'logps/chosen': -102.33970642089844, 'logits/rejected': 239.73602294921875, 'logits/chosen': 239.28834533691406, 'epoch': 3.3}\n",
            "{'loss': 0.2221, 'grad_norm': 1.1604055166244507, 'learning_rate': 0.0001, 'rewards/chosen': 0.40958383679389954, 'rewards/rejected': -1.1075174808502197, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5171012878417969, 'logps/rejected': -67.95468139648438, 'logps/chosen': -144.1041717529297, 'logits/rejected': 238.5537109375, 'logits/chosen': 239.51397705078125, 'epoch': 3.48}\n",
            " 20% 20/100 [00:36<02:29,  1.86s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.28it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 13.13it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.23it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.22854846715927124, 'eval_runtime': 0.7688, 'eval_samples_per_second': 10.405, 'eval_steps_per_second': 10.405, 'eval_rewards/chosen': 0.40363407135009766, 'eval_rewards/rejected': -1.0918536186218262, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 1.4954875707626343, 'eval_logps/rejected': -51.27137756347656, 'eval_logps/chosen': -129.60487365722656, 'eval_logits/rejected': 233.31951904296875, 'eval_logits/chosen': 229.49659729003906, 'epoch': 3.48}\n",
            " 20% 20/100 [00:37<02:29,  1.86s/it]\n",
            "100% 8/8 [00:00<00:00, 11.06it/s]\u001b[A\n",
            "{'loss': 0.1643, 'grad_norm': 1.123347520828247, 'learning_rate': 0.000105, 'rewards/chosen': 0.3950543701648712, 'rewards/rejected': -1.5718486309051514, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9669029712677002, 'logps/rejected': -102.5267333984375, 'logps/chosen': -129.19366455078125, 'logits/rejected': 239.3550567626953, 'logits/chosen': 239.10867309570312, 'epoch': 3.65}\n",
            "{'loss': 0.1563, 'grad_norm': 0.946914792060852, 'learning_rate': 0.00011, 'rewards/chosen': 0.43051204085350037, 'rewards/rejected': -1.6844961643218994, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1150083541870117, 'logps/rejected': -101.2790298461914, 'logps/chosen': -185.34962463378906, 'logits/rejected': 241.06202697753906, 'logits/chosen': 240.09283447265625, 'epoch': 3.83}\n",
            "{'loss': 0.2044, 'grad_norm': 1.8891818523406982, 'learning_rate': 0.000115, 'rewards/chosen': -0.11431082338094711, 'rewards/rejected': -1.9378424882888794, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8235316276550293, 'logps/rejected': -78.87879943847656, 'logps/chosen': -182.47085571289062, 'logits/rejected': 239.43605041503906, 'logits/chosen': 238.47219848632812, 'epoch': 4.0}\n",
            "{'loss': 0.1186, 'grad_norm': 1.1670467853546143, 'learning_rate': 0.00012, 'rewards/chosen': 0.39832356572151184, 'rewards/rejected': -2.0785841941833496, 'rewards/accuracies': 1.0, 'rewards/margins': 2.476907730102539, 'logps/rejected': -74.22298431396484, 'logps/chosen': -147.725830078125, 'logits/rejected': 240.5707550048828, 'logits/chosen': 240.38958740234375, 'epoch': 4.17}\n",
            "{'loss': 0.0467, 'grad_norm': 0.4499860405921936, 'learning_rate': 0.000125, 'rewards/chosen': 0.4158003330230713, 'rewards/rejected': -3.0054941177368164, 'rewards/accuracies': 1.0, 'rewards/margins': 3.4212944507598877, 'logps/rejected': -135.11106872558594, 'logps/chosen': -206.71124267578125, 'logits/rejected': 240.27565002441406, 'logits/chosen': 240.1947479248047, 'epoch': 4.35}\n",
            "{'loss': 0.0798, 'grad_norm': 0.7009045481681824, 'learning_rate': 0.00013000000000000002, 'rewards/chosen': 0.17565838992595673, 'rewards/rejected': -2.6166040897369385, 'rewards/accuracies': 1.0, 'rewards/margins': 2.792262315750122, 'logps/rejected': -75.47223663330078, 'logps/chosen': -116.60765075683594, 'logits/rejected': 238.2210235595703, 'logits/chosen': 237.144775390625, 'epoch': 4.52}\n",
            "{'loss': 0.0703, 'grad_norm': 0.851848840713501, 'learning_rate': 0.000135, 'rewards/chosen': -0.02338305488228798, 'rewards/rejected': -3.4672131538391113, 'rewards/accuracies': 1.0, 'rewards/margins': 3.4438300132751465, 'logps/rejected': -109.24714660644531, 'logps/chosen': -182.4591064453125, 'logits/rejected': 241.3854522705078, 'logits/chosen': 240.13232421875, 'epoch': 4.7}\n",
            "{'loss': 0.0484, 'grad_norm': 0.41469743847846985, 'learning_rate': 0.00014000000000000001, 'rewards/chosen': 0.09381431341171265, 'rewards/rejected': -3.4959194660186768, 'rewards/accuracies': 1.0, 'rewards/margins': 3.589733600616455, 'logps/rejected': -100.72053527832031, 'logps/chosen': -124.53791809082031, 'logits/rejected': 237.34603881835938, 'logits/chosen': 236.48863220214844, 'epoch': 4.87}\n",
            "{'loss': 0.056, 'grad_norm': 0.7458997368812561, 'learning_rate': 0.000145, 'rewards/chosen': -0.14377336204051971, 'rewards/rejected': -3.663455009460449, 'rewards/accuracies': 1.0, 'rewards/margins': 3.519681930541992, 'logps/rejected': -86.39136505126953, 'logps/chosen': -75.32022094726562, 'logits/rejected': 230.35108947753906, 'logits/chosen': 229.86865234375, 'epoch': 5.04}\n",
            "{'loss': 0.0346, 'grad_norm': 0.6915901303291321, 'learning_rate': 0.00015, 'rewards/chosen': -0.009517461061477661, 'rewards/rejected': -4.088335037231445, 'rewards/accuracies': 1.0, 'rewards/margins': 4.078817367553711, 'logps/rejected': -85.84922790527344, 'logps/chosen': -100.24687194824219, 'logits/rejected': 233.93968200683594, 'logits/chosen': 232.58200073242188, 'epoch': 5.22}\n",
            " 30% 30/100 [00:55<01:55,  1.64s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 17.63it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 13.10it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.35it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.029758013784885406, 'eval_runtime': 0.7711, 'eval_samples_per_second': 10.375, 'eval_steps_per_second': 10.375, 'eval_rewards/chosen': 0.22845779359340668, 'eval_rewards/rejected': -3.9207210540771484, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 4.149178504943848, 'eval_logps/rejected': -79.56005096435547, 'eval_logps/chosen': -131.35662841796875, 'eval_logits/rejected': 229.2699737548828, 'eval_logits/chosen': 224.14822387695312, 'epoch': 5.22}\n",
            " 30% 30/100 [00:56<01:55,  1.64s/it]\n",
            "100% 8/8 [00:00<00:00, 11.10it/s]\u001b[A\n",
            "{'loss': 0.011, 'grad_norm': 0.13761235773563385, 'learning_rate': 0.000155, 'rewards/chosen': 0.22295640408992767, 'rewards/rejected': -4.783585071563721, 'rewards/accuracies': 1.0, 'rewards/margins': 5.0065412521362305, 'logps/rejected': -128.80015563964844, 'logps/chosen': -148.99520874023438, 'logits/rejected': 235.76165771484375, 'logits/chosen': 233.72817993164062, 'epoch': 5.39}\n",
            "{'loss': 0.0215, 'grad_norm': 0.46661150455474854, 'learning_rate': 0.00016, 'rewards/chosen': -0.23633639514446259, 'rewards/rejected': -5.250027179718018, 'rewards/accuracies': 1.0, 'rewards/margins': 5.013690948486328, 'logps/rejected': -130.38412475585938, 'logps/chosen': -251.0645751953125, 'logits/rejected': 236.37823486328125, 'logits/chosen': 234.87930297851562, 'epoch': 5.57}\n",
            "{'loss': 0.016, 'grad_norm': 0.2988574802875519, 'learning_rate': 0.000165, 'rewards/chosen': -0.09559620916843414, 'rewards/rejected': -5.410883903503418, 'rewards/accuracies': 1.0, 'rewards/margins': 5.3152875900268555, 'logps/rejected': -114.28792572021484, 'logps/chosen': -118.04264068603516, 'logits/rejected': 231.29515075683594, 'logits/chosen': 229.54437255859375, 'epoch': 5.74}\n",
            "{'loss': 0.0079, 'grad_norm': 0.13651904463768005, 'learning_rate': 0.00017, 'rewards/chosen': -0.4326626658439636, 'rewards/rejected': -6.580154895782471, 'rewards/accuracies': 1.0, 'rewards/margins': 6.147492408752441, 'logps/rejected': -142.64474487304688, 'logps/chosen': -182.9348602294922, 'logits/rejected': 232.0703887939453, 'logits/chosen': 228.33316040039062, 'epoch': 5.91}\n",
            "{'loss': 0.0063, 'grad_norm': 0.15873785316944122, 'learning_rate': 0.000175, 'rewards/chosen': -0.28464967012405396, 'rewards/rejected': -6.507419586181641, 'rewards/accuracies': 1.0, 'rewards/margins': 6.2227702140808105, 'logps/rejected': -128.73255920410156, 'logps/chosen': -65.60478973388672, 'logits/rejected': 230.42333984375, 'logits/chosen': 212.50338745117188, 'epoch': 6.09}\n",
            "{'loss': 0.0034, 'grad_norm': 0.1002541035413742, 'learning_rate': 0.00017999999999999998, 'rewards/chosen': 0.16305088996887207, 'rewards/rejected': -6.17305850982666, 'rewards/accuracies': 1.0, 'rewards/margins': 6.336109161376953, 'logps/rejected': -132.673583984375, 'logps/chosen': -186.06597900390625, 'logits/rejected': 231.59751892089844, 'logits/chosen': 225.88758850097656, 'epoch': 6.26}\n",
            "{'loss': 0.0047, 'grad_norm': 0.11876489222049713, 'learning_rate': 0.000185, 'rewards/chosen': -0.4399409890174866, 'rewards/rejected': -7.1992058753967285, 'rewards/accuracies': 1.0, 'rewards/margins': 6.759264945983887, 'logps/rejected': -116.448486328125, 'logps/chosen': -119.95416259765625, 'logits/rejected': 228.72177124023438, 'logits/chosen': 221.2999267578125, 'epoch': 6.43}\n",
            "{'loss': 0.0046, 'grad_norm': 0.11935954540967941, 'learning_rate': 0.00019, 'rewards/chosen': -1.0854426622390747, 'rewards/rejected': -7.487375259399414, 'rewards/accuracies': 1.0, 'rewards/margins': 6.401932716369629, 'logps/rejected': -151.59088134765625, 'logps/chosen': -225.18310546875, 'logits/rejected': 233.31080627441406, 'logits/chosen': 229.59634399414062, 'epoch': 6.61}\n",
            "{'loss': 0.001, 'grad_norm': 0.022235898301005363, 'learning_rate': 0.00019500000000000002, 'rewards/chosen': 0.10118750482797623, 'rewards/rejected': -7.678328514099121, 'rewards/accuracies': 1.0, 'rewards/margins': 7.779516220092773, 'logps/rejected': -134.66587829589844, 'logps/chosen': -159.8648223876953, 'logits/rejected': 231.05311584472656, 'logits/chosen': 225.980712890625, 'epoch': 6.78}\n",
            "{'loss': 0.0023, 'grad_norm': 0.05422227829694748, 'learning_rate': 0.0002, 'rewards/chosen': -0.9447438716888428, 'rewards/rejected': -9.112799644470215, 'rewards/accuracies': 1.0, 'rewards/margins': 8.16805648803711, 'logps/rejected': -166.76063537597656, 'logps/chosen': -121.92840576171875, 'logits/rejected': 223.173583984375, 'logits/chosen': 212.38616943359375, 'epoch': 6.96}\n",
            " 40% 40/100 [01:13<01:44,  1.74s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 17.93it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 12.96it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.22it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.0013224894646555185, 'eval_runtime': 0.7689, 'eval_samples_per_second': 10.405, 'eval_steps_per_second': 10.405, 'eval_rewards/chosen': -0.10419218242168427, 'eval_rewards/rejected': -7.432766437530518, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 7.328575134277344, 'eval_logps/rejected': -114.68050384521484, 'eval_logps/chosen': -134.68313598632812, 'eval_logits/rejected': 219.65753173828125, 'eval_logits/chosen': 212.10586547851562, 'epoch': 6.96}\n",
            " 40% 40/100 [01:14<01:44,  1.74s/it]\n",
            "100% 8/8 [00:00<00:00, 11.10it/s]\u001b[A\n",
            "{'loss': 0.0009, 'grad_norm': 0.033437784761190414, 'learning_rate': 0.000205, 'rewards/chosen': -0.9692489504814148, 'rewards/rejected': -8.669220924377441, 'rewards/accuracies': 1.0, 'rewards/margins': 7.699972152709961, 'logps/rejected': -140.999267578125, 'logps/chosen': -68.61907958984375, 'logits/rejected': 221.4807586669922, 'logits/chosen': 210.34718322753906, 'epoch': 7.13}\n",
            "{'loss': 0.0006, 'grad_norm': 0.01547984965145588, 'learning_rate': 0.00021, 'rewards/chosen': -0.34619995951652527, 'rewards/rejected': -8.981901168823242, 'rewards/accuracies': 1.0, 'rewards/margins': 8.635702133178711, 'logps/rejected': -159.35072326660156, 'logps/chosen': -154.2745819091797, 'logits/rejected': 222.93902587890625, 'logits/chosen': 208.7633056640625, 'epoch': 7.3}\n",
            "{'loss': 0.0012, 'grad_norm': 0.048996251076459885, 'learning_rate': 0.000215, 'rewards/chosen': -0.6707936525344849, 'rewards/rejected': -8.879971504211426, 'rewards/accuracies': 1.0, 'rewards/margins': 8.209177017211914, 'logps/rejected': -128.69622802734375, 'logps/chosen': -175.9792938232422, 'logits/rejected': 223.1544952392578, 'logits/chosen': 216.47784423828125, 'epoch': 7.48}\n",
            "{'loss': 0.0004, 'grad_norm': 0.014297179877758026, 'learning_rate': 0.00022, 'rewards/chosen': -1.332766056060791, 'rewards/rejected': -10.389029502868652, 'rewards/accuracies': 1.0, 'rewards/margins': 9.05626392364502, 'logps/rejected': -187.0586395263672, 'logps/chosen': -181.17584228515625, 'logits/rejected': 223.44117736816406, 'logits/chosen': 220.14767456054688, 'epoch': 7.65}\n",
            "{'loss': 0.001, 'grad_norm': 0.043012529611587524, 'learning_rate': 0.00022500000000000002, 'rewards/chosen': -2.661902904510498, 'rewards/rejected': -11.808067321777344, 'rewards/accuracies': 1.0, 'rewards/margins': 9.146164894104004, 'logps/rejected': -203.974365234375, 'logps/chosen': -191.15057373046875, 'logits/rejected': 222.72412109375, 'logits/chosen': 205.62481689453125, 'epoch': 7.83}\n",
            "{'loss': 0.0004, 'grad_norm': 0.016640285030007362, 'learning_rate': 0.00023, 'rewards/chosen': -1.7881274223327637, 'rewards/rejected': -11.44825553894043, 'rewards/accuracies': 1.0, 'rewards/margins': 9.660128593444824, 'logps/rejected': -180.94302368164062, 'logps/chosen': -154.6490020751953, 'logits/rejected': 214.83908081054688, 'logits/chosen': 196.91986083984375, 'epoch': 8.0}\n",
            "{'loss': 0.0002, 'grad_norm': 0.007723724469542503, 'learning_rate': 0.000235, 'rewards/chosen': -1.3247987031936646, 'rewards/rejected': -11.903656005859375, 'rewards/accuracies': 1.0, 'rewards/margins': 10.578858375549316, 'logps/rejected': -195.27606201171875, 'logps/chosen': -204.29188537597656, 'logits/rejected': 221.70236206054688, 'logits/chosen': 212.3985137939453, 'epoch': 8.17}\n",
            "{'loss': 0.0006, 'grad_norm': 0.05002252012491226, 'learning_rate': 0.00024, 'rewards/chosen': -1.9772272109985352, 'rewards/rejected': -11.86151123046875, 'rewards/accuracies': 1.0, 'rewards/margins': 9.884284019470215, 'logps/rejected': -173.2908172607422, 'logps/chosen': -188.0433807373047, 'logits/rejected': 209.9809112548828, 'logits/chosen': 198.59820556640625, 'epoch': 8.35}\n",
            "{'loss': 0.0006, 'grad_norm': 0.07382406294345856, 'learning_rate': 0.000245, 'rewards/chosen': -2.824958324432373, 'rewards/rejected': -13.857682228088379, 'rewards/accuracies': 1.0, 'rewards/margins': 11.032722473144531, 'logps/rejected': -199.00875854492188, 'logps/chosen': -117.5296859741211, 'logits/rejected': 205.7735137939453, 'logits/chosen': 183.8520965576172, 'epoch': 8.52}\n",
            "{'loss': 0.0003, 'grad_norm': 0.010862641967833042, 'learning_rate': 0.00025, 'rewards/chosen': -0.7925271391868591, 'rewards/rejected': -10.858867645263672, 'rewards/accuracies': 1.0, 'rewards/margins': 10.066340446472168, 'logps/rejected': -162.16629028320312, 'logps/chosen': -82.79695892333984, 'logits/rejected': 199.97830200195312, 'logits/chosen': 185.19351196289062, 'epoch': 8.7}\n",
            " 50% 50/100 [01:31<01:22,  1.65s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.32it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 13.51it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.44it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.00018610048573464155, 'eval_runtime': 0.767, 'eval_samples_per_second': 10.43, 'eval_steps_per_second': 10.43, 'eval_rewards/chosen': -1.5463383197784424, 'eval_rewards/rejected': -11.467215538024902, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 9.920876502990723, 'eval_logps/rejected': -155.0249786376953, 'eval_logps/chosen': -149.10459899902344, 'eval_logits/rejected': 194.63006591796875, 'eval_logits/chosen': 188.9967498779297, 'epoch': 8.7}\n",
            " 50% 50/100 [01:31<01:22,  1.65s/it]\n",
            "100% 8/8 [00:00<00:00, 11.07it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "{'loss': 0.0003, 'grad_norm': 0.019927099347114563, 'learning_rate': 0.000255, 'rewards/chosen': -4.569082260131836, 'rewards/rejected': -15.417752265930176, 'rewards/accuracies': 1.0, 'rewards/margins': 10.848670959472656, 'logps/rejected': -244.841064453125, 'logps/chosen': -240.28077697753906, 'logits/rejected': 209.70669555664062, 'logits/chosen': 190.73184204101562, 'epoch': 8.87}\n",
            "{'loss': 0.0002, 'grad_norm': 0.014364124275743961, 'learning_rate': 0.00026000000000000003, 'rewards/chosen': -2.520148277282715, 'rewards/rejected': -13.230772018432617, 'rewards/accuracies': 1.0, 'rewards/margins': 10.710624694824219, 'logps/rejected': -190.3909912109375, 'logps/chosen': -153.2147979736328, 'logits/rejected': 199.07550048828125, 'logits/chosen': 180.9691619873047, 'epoch': 9.04}\n",
            "{'loss': 0.0001, 'grad_norm': 0.010363820940256119, 'learning_rate': 0.00026500000000000004, 'rewards/chosen': -2.95145320892334, 'rewards/rejected': -14.813423156738281, 'rewards/accuracies': 1.0, 'rewards/margins': 11.861969947814941, 'logps/rejected': -229.3311004638672, 'logps/chosen': -200.99449157714844, 'logits/rejected': 205.58758544921875, 'logits/chosen': 192.70838928222656, 'epoch': 9.22}\n",
            "{'loss': 0.0001, 'grad_norm': 0.006161537021398544, 'learning_rate': 0.00027, 'rewards/chosen': -2.978076219558716, 'rewards/rejected': -14.132120132446289, 'rewards/accuracies': 1.0, 'rewards/margins': 11.154044151306152, 'logps/rejected': -207.140380859375, 'logps/chosen': -123.60620880126953, 'logits/rejected': 188.68641662597656, 'logits/chosen': 151.44915771484375, 'epoch': 9.39}\n",
            "{'loss': 0.0002, 'grad_norm': 0.013235660269856453, 'learning_rate': 0.000275, 'rewards/chosen': -2.774214506149292, 'rewards/rejected': -14.385150909423828, 'rewards/accuracies': 1.0, 'rewards/margins': 11.61093521118164, 'logps/rejected': -213.60617065429688, 'logps/chosen': -248.74600219726562, 'logits/rejected': 199.6869659423828, 'logits/chosen': 195.87429809570312, 'epoch': 9.57}\n",
            "{'loss': 0.0002, 'grad_norm': 0.010289348661899567, 'learning_rate': 0.00028000000000000003, 'rewards/chosen': -3.585759162902832, 'rewards/rejected': -14.057168960571289, 'rewards/accuracies': 1.0, 'rewards/margins': 10.471410751342773, 'logps/rejected': -212.73899841308594, 'logps/chosen': -206.31845092773438, 'logits/rejected': 195.1666717529297, 'logits/chosen': 191.1594696044922, 'epoch': 9.74}\n",
            "{'loss': 0.0001, 'grad_norm': 0.006247591692954302, 'learning_rate': 0.000285, 'rewards/chosen': -2.3852479457855225, 'rewards/rejected': -14.641740798950195, 'rewards/accuracies': 1.0, 'rewards/margins': 12.25649356842041, 'logps/rejected': -202.87803649902344, 'logps/chosen': -155.69473266601562, 'logits/rejected': 195.02313232421875, 'logits/chosen': 174.869384765625, 'epoch': 9.91}\n",
            "{'loss': 0.0, 'grad_norm': 0.003379345638677478, 'learning_rate': 0.00029, 'rewards/chosen': -3.1752099990844727, 'rewards/rejected': -15.206306457519531, 'rewards/accuracies': 1.0, 'rewards/margins': 12.031095504760742, 'logps/rejected': -206.2122802734375, 'logps/chosen': -157.46163940429688, 'logits/rejected': 196.1370849609375, 'logits/chosen': 176.90548706054688, 'epoch': 10.09}\n",
            "{'loss': 0.0, 'grad_norm': 0.0017755358712747693, 'learning_rate': 0.000295, 'rewards/chosen': -4.512836456298828, 'rewards/rejected': -16.611270904541016, 'rewards/accuracies': 1.0, 'rewards/margins': 12.098434448242188, 'logps/rejected': -230.4464111328125, 'logps/chosen': -153.28379821777344, 'logits/rejected': 182.23106384277344, 'logits/chosen': 164.67633056640625, 'epoch': 10.26}\n",
            "{'loss': 0.0001, 'grad_norm': 0.006265431642532349, 'learning_rate': 0.0003, 'rewards/chosen': -3.473297119140625, 'rewards/rejected': -16.28644561767578, 'rewards/accuracies': 1.0, 'rewards/margins': 12.813149452209473, 'logps/rejected': -221.9300079345703, 'logps/chosen': -191.0754852294922, 'logits/rejected': 180.08200073242188, 'logits/chosen': 151.2253875732422, 'epoch': 10.43}\n",
            " 60% 60/100 [01:49<01:06,  1.67s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.53it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 12.70it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 11.44it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 6.319940439425409e-05, 'eval_runtime': 0.8026, 'eval_samples_per_second': 9.968, 'eval_steps_per_second': 9.968, 'eval_rewards/chosen': -2.2781341075897217, 'eval_rewards/rejected': -13.878813743591309, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 11.600680351257324, 'eval_logps/rejected': -179.1409912109375, 'eval_logps/chosen': -156.42254638671875, 'eval_logits/rejected': 174.74319458007812, 'eval_logits/chosen': 171.30706787109375, 'epoch': 10.43}\n",
            " 60% 60/100 [01:50<01:06,  1.67s/it]\n",
            "100% 8/8 [00:00<00:00, 10.51it/s]\u001b[A\n",
            "{'loss': 0.0002, 'grad_norm': 0.008212736807763577, 'learning_rate': 0.000305, 'rewards/chosen': -2.6903538703918457, 'rewards/rejected': -13.907764434814453, 'rewards/accuracies': 1.0, 'rewards/margins': 11.217411041259766, 'logps/rejected': -206.19207763671875, 'logps/chosen': -213.55935668945312, 'logits/rejected': 201.32196044921875, 'logits/chosen': 198.41256713867188, 'epoch': 10.61}\n",
            "{'loss': 0.0, 'grad_norm': 0.002025753725320101, 'learning_rate': 0.00031, 'rewards/chosen': -2.7784996032714844, 'rewards/rejected': -16.258697509765625, 'rewards/accuracies': 1.0, 'rewards/margins': 13.480196952819824, 'logps/rejected': -229.7987518310547, 'logps/chosen': -106.79574584960938, 'logits/rejected': 180.830078125, 'logits/chosen': 154.4226531982422, 'epoch': 10.78}\n",
            "{'loss': 0.0, 'grad_norm': 0.0033054854720830917, 'learning_rate': 0.000315, 'rewards/chosen': -4.12544059753418, 'rewards/rejected': -16.95501708984375, 'rewards/accuracies': 1.0, 'rewards/margins': 12.82957649230957, 'logps/rejected': -243.7986297607422, 'logps/chosen': -241.25753784179688, 'logits/rejected': 189.21669006347656, 'logits/chosen': 168.44711303710938, 'epoch': 10.96}\n",
            "{'loss': 0.0, 'grad_norm': 0.002768959617242217, 'learning_rate': 0.00032, 'rewards/chosen': -3.0685746669769287, 'rewards/rejected': -14.843953132629395, 'rewards/accuracies': 1.0, 'rewards/margins': 11.775378227233887, 'logps/rejected': -224.5225830078125, 'logps/chosen': -200.07899475097656, 'logits/rejected': 185.80978393554688, 'logits/chosen': 175.39955139160156, 'epoch': 11.13}\n",
            "{'loss': 0.0, 'grad_norm': 0.002035809215158224, 'learning_rate': 0.00032500000000000004, 'rewards/chosen': -3.9691061973571777, 'rewards/rejected': -18.59360122680664, 'rewards/accuracies': 1.0, 'rewards/margins': 14.624494552612305, 'logps/rejected': -247.94041442871094, 'logps/chosen': -147.80160522460938, 'logits/rejected': 180.40859985351562, 'logits/chosen': 149.50033569335938, 'epoch': 11.3}\n",
            "{'loss': 0.0, 'grad_norm': 0.0007909004925750196, 'learning_rate': 0.00033, 'rewards/chosen': -4.442934513092041, 'rewards/rejected': -19.14797592163086, 'rewards/accuracies': 1.0, 'rewards/margins': 14.705039978027344, 'logps/rejected': -271.1854248046875, 'logps/chosen': -147.58567810058594, 'logits/rejected': 180.71849060058594, 'logits/chosen': 150.09307861328125, 'epoch': 11.48}\n",
            "{'loss': 0.0001, 'grad_norm': 0.003974585328251123, 'learning_rate': 0.000335, 'rewards/chosen': -3.2999277114868164, 'rewards/rejected': -15.253490447998047, 'rewards/accuracies': 1.0, 'rewards/margins': 11.95356273651123, 'logps/rejected': -221.00851440429688, 'logps/chosen': -204.70169067382812, 'logits/rejected': 187.08511352539062, 'logits/chosen': 181.3463134765625, 'epoch': 11.65}\n",
            "{'loss': 0.0, 'grad_norm': 0.002040273044258356, 'learning_rate': 0.00034, 'rewards/chosen': -4.498200416564941, 'rewards/rejected': -16.900680541992188, 'rewards/accuracies': 1.0, 'rewards/margins': 12.402481079101562, 'logps/rejected': -229.17340087890625, 'logps/chosen': -209.80523681640625, 'logits/rejected': 173.6874237060547, 'logits/chosen': 155.7845916748047, 'epoch': 11.83}\n",
            "{'loss': 0.0, 'grad_norm': 0.002930372254922986, 'learning_rate': 0.000345, 'rewards/chosen': -1.7454524040222168, 'rewards/rejected': -14.401609420776367, 'rewards/accuracies': 1.0, 'rewards/margins': 12.656158447265625, 'logps/rejected': -200.6475830078125, 'logps/chosen': -195.2074737548828, 'logits/rejected': 186.4590301513672, 'logits/chosen': 179.38816833496094, 'epoch': 12.0}\n",
            "{'loss': 0.0, 'grad_norm': 0.0025792785454541445, 'learning_rate': 0.00035, 'rewards/chosen': -2.52079439163208, 'rewards/rejected': -15.597089767456055, 'rewards/accuracies': 1.0, 'rewards/margins': 13.0762939453125, 'logps/rejected': -210.94390869140625, 'logps/chosen': -85.86555480957031, 'logits/rejected': 169.169921875, 'logits/chosen': 151.1344451904297, 'epoch': 12.17}\n",
            " 70% 70/100 [02:07<00:46,  1.56s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.50it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 13.33it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 12.38it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.48616813425906e-05, 'eval_runtime': 0.7638, 'eval_samples_per_second': 10.474, 'eval_steps_per_second': 10.474, 'eval_rewards/chosen': -2.612739086151123, 'eval_rewards/rejected': -15.131447792053223, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 12.518709182739258, 'eval_logps/rejected': -191.66732788085938, 'eval_logps/chosen': -159.7686004638672, 'eval_logits/rejected': 162.1516571044922, 'eval_logits/chosen': 160.45213317871094, 'epoch': 12.17}\n",
            " 70% 70/100 [02:07<00:46,  1.56s/it]\n",
            "100% 8/8 [00:00<00:00, 11.09it/s]\u001b[A\n",
            "{'loss': 0.0, 'grad_norm': 0.0013321980368345976, 'learning_rate': 0.000355, 'rewards/chosen': -3.8910040855407715, 'rewards/rejected': -19.15138816833496, 'rewards/accuracies': 1.0, 'rewards/margins': 15.260383605957031, 'logps/rejected': -258.9093933105469, 'logps/chosen': -167.00177001953125, 'logits/rejected': 176.24929809570312, 'logits/chosen': 146.665283203125, 'epoch': 12.35}\n",
            "{'loss': 0.0, 'grad_norm': 0.002499490510672331, 'learning_rate': 0.00035999999999999997, 'rewards/chosen': -4.46608829498291, 'rewards/rejected': -18.324886322021484, 'rewards/accuracies': 1.0, 'rewards/margins': 13.858797073364258, 'logps/rejected': -268.64874267578125, 'logps/chosen': -210.88284301757812, 'logits/rejected': 183.75990295410156, 'logits/chosen': 169.86956787109375, 'epoch': 12.52}\n",
            "{'loss': 0.0, 'grad_norm': 0.0012914967956021428, 'learning_rate': 0.000365, 'rewards/chosen': -3.152235984802246, 'rewards/rejected': -16.545013427734375, 'rewards/accuracies': 1.0, 'rewards/margins': 13.392778396606445, 'logps/rejected': -221.33995056152344, 'logps/chosen': -153.1409454345703, 'logits/rejected': 167.6363525390625, 'logits/chosen': 151.23410034179688, 'epoch': 12.7}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006851353100501001, 'learning_rate': 0.00037, 'rewards/chosen': -4.361488342285156, 'rewards/rejected': -17.500492095947266, 'rewards/accuracies': 1.0, 'rewards/margins': 13.139001846313477, 'logps/rejected': -234.7666015625, 'logps/chosen': -262.2039489746094, 'logits/rejected': 169.12551879882812, 'logits/chosen': 163.32066345214844, 'epoch': 12.87}\n",
            "{'loss': 0.0, 'grad_norm': 0.001860894146375358, 'learning_rate': 0.000375, 'rewards/chosen': -3.6657021045684814, 'rewards/rejected': -15.716686248779297, 'rewards/accuracies': 1.0, 'rewards/margins': 12.050983428955078, 'logps/rejected': -224.3734130859375, 'logps/chosen': -253.34498596191406, 'logits/rejected': 175.93113708496094, 'logits/chosen': 180.4579620361328, 'epoch': 13.04}\n",
            "{'loss': 0.0, 'grad_norm': 0.0017955180956050754, 'learning_rate': 0.00038, 'rewards/chosen': -4.771869659423828, 'rewards/rejected': -18.21566390991211, 'rewards/accuracies': 1.0, 'rewards/margins': 13.443796157836914, 'logps/rejected': -262.67803955078125, 'logps/chosen': -241.78237915039062, 'logits/rejected': 165.3729248046875, 'logits/chosen': 150.47283935546875, 'epoch': 13.22}\n",
            "{'loss': 0.0, 'grad_norm': 0.0010190150933340192, 'learning_rate': 0.00038500000000000003, 'rewards/chosen': -4.55989933013916, 'rewards/rejected': -17.596817016601562, 'rewards/accuracies': 1.0, 'rewards/margins': 13.036919593811035, 'logps/rejected': -260.3813171386719, 'logps/chosen': -235.6978302001953, 'logits/rejected': 173.86936950683594, 'logits/chosen': 170.26217651367188, 'epoch': 13.39}\n",
            "{'loss': 0.0, 'grad_norm': 0.001056857407093048, 'learning_rate': 0.00039000000000000005, 'rewards/chosen': -4.58526611328125, 'rewards/rejected': -18.28959846496582, 'rewards/accuracies': 1.0, 'rewards/margins': 13.704331398010254, 'logps/rejected': -246.85153198242188, 'logps/chosen': -202.83279418945312, 'logits/rejected': 172.49436950683594, 'logits/chosen': 158.38973999023438, 'epoch': 13.57}\n",
            "{'loss': 0.0, 'grad_norm': 0.0013012128183618188, 'learning_rate': 0.000395, 'rewards/chosen': -4.308677673339844, 'rewards/rejected': -20.55030059814453, 'rewards/accuracies': 1.0, 'rewards/margins': 16.241622924804688, 'logps/rejected': -282.43988037109375, 'logps/chosen': -128.91749572753906, 'logits/rejected': 161.15829467773438, 'logits/chosen': 126.53116607666016, 'epoch': 13.74}\n",
            "{'loss': 0.0, 'grad_norm': 0.0012296350905671716, 'learning_rate': 0.0004, 'rewards/chosen': -2.429185628890991, 'rewards/rejected': -16.663928985595703, 'rewards/accuracies': 1.0, 'rewards/margins': 14.2347412109375, 'logps/rejected': -211.61099243164062, 'logps/chosen': -133.59912109375, 'logits/rejected': 169.36512756347656, 'logits/chosen': 131.696044921875, 'epoch': 13.91}\n",
            " 80% 80/100 [02:25<00:33,  1.66s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.60it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 12.61it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 11.84it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 2.1977106371195987e-05, 'eval_runtime': 0.7786, 'eval_samples_per_second': 10.275, 'eval_steps_per_second': 10.275, 'eval_rewards/chosen': -2.7478785514831543, 'eval_rewards/rejected': -15.834428787231445, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 13.086549758911133, 'eval_logps/rejected': -198.69711303710938, 'eval_logps/chosen': -161.12001037597656, 'eval_logits/rejected': 154.11083984375, 'eval_logits/chosen': 153.92080688476562, 'epoch': 13.91}\n",
            " 80% 80/100 [02:25<00:33,  1.66s/it]\n",
            "100% 8/8 [00:00<00:00, 10.91it/s]\u001b[A\n",
            "{'loss': 0.0, 'grad_norm': 0.001445411005988717, 'learning_rate': 0.00040500000000000003, 'rewards/chosen': -3.752609968185425, 'rewards/rejected': -17.41473388671875, 'rewards/accuracies': 1.0, 'rewards/margins': 13.662125587463379, 'logps/rejected': -230.62255859375, 'logps/chosen': -148.85134887695312, 'logits/rejected': 174.3617401123047, 'logits/chosen': 166.78570556640625, 'epoch': 14.09}\n",
            "{'loss': 0.0, 'grad_norm': 0.0010944224195554852, 'learning_rate': 0.00041, 'rewards/chosen': -4.679444313049316, 'rewards/rejected': -17.525175094604492, 'rewards/accuracies': 1.0, 'rewards/margins': 12.845731735229492, 'logps/rejected': -256.7837219238281, 'logps/chosen': -254.51171875, 'logits/rejected': 176.6111602783203, 'logits/chosen': 159.7798614501953, 'epoch': 14.26}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005682124756276608, 'learning_rate': 0.000415, 'rewards/chosen': -4.382816314697266, 'rewards/rejected': -20.222492218017578, 'rewards/accuracies': 1.0, 'rewards/margins': 15.839675903320312, 'logps/rejected': -281.3954162597656, 'logps/chosen': -238.0953826904297, 'logits/rejected': 168.47117614746094, 'logits/chosen': 155.14601135253906, 'epoch': 14.43}\n",
            "{'loss': 0.0, 'grad_norm': 0.0012426296016201377, 'learning_rate': 0.00042, 'rewards/chosen': -4.6121320724487305, 'rewards/rejected': -18.989547729492188, 'rewards/accuracies': 1.0, 'rewards/margins': 14.377415657043457, 'logps/rejected': -265.78887939453125, 'logps/chosen': -193.90899658203125, 'logits/rejected': 184.5108184814453, 'logits/chosen': 138.1356658935547, 'epoch': 14.61}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006394898518919945, 'learning_rate': 0.000425, 'rewards/chosen': -2.0571651458740234, 'rewards/rejected': -16.533645629882812, 'rewards/accuracies': 1.0, 'rewards/margins': 14.476480484008789, 'logps/rejected': -218.44189453125, 'logps/chosen': -149.56027221679688, 'logits/rejected': 161.89495849609375, 'logits/chosen': 139.1296844482422, 'epoch': 14.78}\n",
            "{'loss': 0.0, 'grad_norm': 0.0009153862483799458, 'learning_rate': 0.00043, 'rewards/chosen': -2.92266845703125, 'rewards/rejected': -16.762863159179688, 'rewards/accuracies': 1.0, 'rewards/margins': 13.840192794799805, 'logps/rejected': -209.87879943847656, 'logps/chosen': -129.34486389160156, 'logits/rejected': 156.51573181152344, 'logits/chosen': 140.4164581298828, 'epoch': 14.96}\n",
            "{'loss': 0.0, 'grad_norm': 0.001178706530481577, 'learning_rate': 0.000435, 'rewards/chosen': -4.567153453826904, 'rewards/rejected': -17.882469177246094, 'rewards/accuracies': 1.0, 'rewards/margins': 13.315316200256348, 'logps/rejected': -248.3184814453125, 'logps/chosen': -221.4108123779297, 'logits/rejected': 171.38186645507812, 'logits/chosen': 168.62428283691406, 'epoch': 15.13}\n",
            "{'loss': 0.0, 'grad_norm': 0.0009469751385040581, 'learning_rate': 0.00044, 'rewards/chosen': -4.393181800842285, 'rewards/rejected': -19.19876480102539, 'rewards/accuracies': 1.0, 'rewards/margins': 14.805583000183105, 'logps/rejected': -270.5344543457031, 'logps/chosen': -194.96800231933594, 'logits/rejected': 170.78370666503906, 'logits/chosen': 137.1389923095703, 'epoch': 15.3}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006174242007546127, 'learning_rate': 0.00044500000000000003, 'rewards/chosen': -4.037294387817383, 'rewards/rejected': -19.49896240234375, 'rewards/accuracies': 1.0, 'rewards/margins': 15.461666107177734, 'logps/rejected': -265.49920654296875, 'logps/chosen': -144.31198120117188, 'logits/rejected': 163.42868041992188, 'logits/chosen': 133.06283569335938, 'epoch': 15.48}\n",
            "{'loss': 0.0, 'grad_norm': 0.0007445159135386348, 'learning_rate': 0.00045000000000000004, 'rewards/chosen': -4.168378829956055, 'rewards/rejected': -17.793270111083984, 'rewards/accuracies': 1.0, 'rewards/margins': 13.62489128112793, 'logps/rejected': -228.1682586669922, 'logps/chosen': -158.64004516601562, 'logits/rejected': 153.42068481445312, 'logits/chosen': 145.4720916748047, 'epoch': 15.65}\n",
            " 90% 90/100 [02:43<00:16,  1.68s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 17.99it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 12.80it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 11.87it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 1.7692515029921196e-05, 'eval_runtime': 0.7979, 'eval_samples_per_second': 10.026, 'eval_steps_per_second': 10.026, 'eval_rewards/chosen': -2.8493316173553467, 'eval_rewards/rejected': -16.298492431640625, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 13.449159622192383, 'eval_logps/rejected': -203.3377685546875, 'eval_logps/chosen': -162.134521484375, 'eval_logits/rejected': 148.5616455078125, 'eval_logits/chosen': 149.675537109375, 'epoch': 15.65}\n",
            " 90% 90/100 [02:44<00:16,  1.68s/it]\n",
            "100% 8/8 [00:00<00:00, 10.50it/s]\u001b[A\n",
            "{'loss': 0.0, 'grad_norm': 0.0007709741475991905, 'learning_rate': 0.000455, 'rewards/chosen': -2.647395610809326, 'rewards/rejected': -17.06723976135254, 'rewards/accuracies': 1.0, 'rewards/margins': 14.419844627380371, 'logps/rejected': -230.03506469726562, 'logps/chosen': -239.62652587890625, 'logits/rejected': 173.51583862304688, 'logits/chosen': 160.89219665527344, 'epoch': 15.83}\n",
            "{'loss': 0.0, 'grad_norm': 0.00022875360446050763, 'learning_rate': 0.00046, 'rewards/chosen': -3.795170307159424, 'rewards/rejected': -19.50244903564453, 'rewards/accuracies': 1.0, 'rewards/margins': 15.707279205322266, 'logps/rejected': -264.01190185546875, 'logps/chosen': -136.65126037597656, 'logits/rejected': 147.27072143554688, 'logits/chosen': 111.96710205078125, 'epoch': 16.0}\n",
            "{'loss': 0.0, 'grad_norm': 0.0007248808979056776, 'learning_rate': 0.000465, 'rewards/chosen': -3.9672398567199707, 'rewards/rejected': -19.186946868896484, 'rewards/accuracies': 1.0, 'rewards/margins': 15.219706535339355, 'logps/rejected': -263.56378173828125, 'logps/chosen': -172.28753662109375, 'logits/rejected': 166.59539794921875, 'logits/chosen': 147.55523681640625, 'epoch': 16.17}\n",
            "{'loss': 0.0, 'grad_norm': 0.0008574416278861463, 'learning_rate': 0.00047, 'rewards/chosen': -3.630018472671509, 'rewards/rejected': -18.368635177612305, 'rewards/accuracies': 1.0, 'rewards/margins': 14.738616943359375, 'logps/rejected': -254.32339477539062, 'logps/chosen': -201.6495361328125, 'logits/rejected': 165.51834106445312, 'logits/chosen': 140.9317169189453, 'epoch': 16.35}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006761396070942283, 'learning_rate': 0.000475, 'rewards/chosen': -4.07248592376709, 'rewards/rejected': -17.880884170532227, 'rewards/accuracies': 1.0, 'rewards/margins': 13.80840015411377, 'logps/rejected': -250.74940490722656, 'logps/chosen': -197.80462646484375, 'logits/rejected': 167.3428955078125, 'logits/chosen': 150.79685974121094, 'epoch': 16.52}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006511521642096341, 'learning_rate': 0.00048, 'rewards/chosen': -3.9080471992492676, 'rewards/rejected': -20.462535858154297, 'rewards/accuracies': 1.0, 'rewards/margins': 16.554485321044922, 'logps/rejected': -259.1575622558594, 'logps/chosen': -138.7259063720703, 'logits/rejected': 137.45379638671875, 'logits/chosen': 124.58537292480469, 'epoch': 16.7}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005123487790115178, 'learning_rate': 0.00048499999999999997, 'rewards/chosen': -5.132004261016846, 'rewards/rejected': -19.51565170288086, 'rewards/accuracies': 1.0, 'rewards/margins': 14.383646011352539, 'logps/rejected': -269.784423828125, 'logps/chosen': -209.87396240234375, 'logits/rejected': 169.1217498779297, 'logits/chosen': 147.49192810058594, 'epoch': 16.87}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005817179335281253, 'learning_rate': 0.00049, 'rewards/chosen': -4.1290788650512695, 'rewards/rejected': -16.93888282775879, 'rewards/accuracies': 1.0, 'rewards/margins': 12.80980396270752, 'logps/rejected': -231.7118682861328, 'logps/chosen': -251.3461456298828, 'logits/rejected': 151.80902099609375, 'logits/chosen': 142.933837890625, 'epoch': 17.04}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005044691497460008, 'learning_rate': 0.000495, 'rewards/chosen': -3.8962321281433105, 'rewards/rejected': -20.043529510498047, 'rewards/accuracies': 1.0, 'rewards/margins': 16.147296905517578, 'logps/rejected': -270.78558349609375, 'logps/chosen': -140.22927856445312, 'logits/rejected': 167.5121612548828, 'logits/chosen': 146.23660278320312, 'epoch': 17.22}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006249202415347099, 'learning_rate': 0.0005, 'rewards/chosen': -3.9264886379241943, 'rewards/rejected': -19.39653778076172, 'rewards/accuracies': 1.0, 'rewards/margins': 15.470048904418945, 'logps/rejected': -252.07398986816406, 'logps/chosen': -159.36631774902344, 'logits/rejected': 156.3627166748047, 'logits/chosen': 121.09330749511719, 'epoch': 17.39}\n",
            "100% 100/100 [03:01<00:00,  1.70s/it]\n",
            "  0% 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25% 2/8 [00:00<00:00, 18.12it/s]\u001b[A\n",
            " 50% 4/8 [00:00<00:00, 12.35it/s]\u001b[A\n",
            " 75% 6/8 [00:00<00:00, 11.85it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.4094135622144677e-05, 'eval_runtime': 0.7882, 'eval_samples_per_second': 10.149, 'eval_steps_per_second': 10.149, 'eval_rewards/chosen': -2.8843331336975098, 'eval_rewards/rejected': -16.583276748657227, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 13.698944091796875, 'eval_logps/rejected': -206.18560791015625, 'eval_logps/chosen': -162.4845428466797, 'eval_logits/rejected': 144.94439697265625, 'eval_logits/chosen': 146.9715118408203, 'epoch': 17.39}\n",
            "100% 100/100 [03:02<00:00,  1.70s/it]\n",
            "100% 8/8 [00:00<00:00, 10.77it/s]\u001b[A\n",
            "                                 \u001b[A/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'train_runtime': 182.9891, 'train_samples_per_second': 6.558, 'train_steps_per_second': 0.546, 'train_loss': 0.11538656047196583, 'epoch': 17.39}\n",
            "100% 100/100 [03:02<00:00,  1.83s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =      17.39\n",
            "  train_loss               =     0.1154\n",
            "  train_runtime            = 0:03:02.98\n",
            "  train_samples            =        100\n",
            "  train_samples_per_second =      6.558\n",
            "  train_steps_per_second   =      0.546\n",
            "\u001b[32m2024-03-08 05:51:27.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m479\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 182.9891, 'train_samples_per_second': 6.558, 'train_steps_per_second': 0.546, 'train_loss': 0.11538656047196583, 'epoch': 17.39, 'train_samples': 100}\u001b[0m\n",
            "\u001b[32m2024-03-08 05:51:27.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m480\u001b[0m - \u001b[1mSaving model checkpoint to outputs-dpo-v1\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in ./merged-sft - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "\u001b[32m2024-03-08 05:51:27.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m487\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 8/8 [00:00<00:00, 11.53it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =      17.39\n",
            "  eval_logits/chosen      =   146.9715\n",
            "  eval_logits/rejected    =   144.9444\n",
            "  eval_logps/chosen       =  -162.4845\n",
            "  eval_logps/rejected     =  -206.1856\n",
            "  eval_loss               =        0.0\n",
            "  eval_rewards/accuracies =        1.0\n",
            "  eval_rewards/chosen     =    -2.8843\n",
            "  eval_rewards/margins    =    13.6989\n",
            "  eval_rewards/rejected   =   -16.5833\n",
            "  eval_runtime            = 0:00:00.79\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =     10.101\n",
            "  eval_steps_per_second   =     10.101\n",
            "\u001b[32m2024-03-08 05:51:28.783\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m493\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 1.4094135622144677e-05, 'eval_runtime': 0.792, 'eval_samples_per_second': 10.101, 'eval_steps_per_second': 10.101, 'eval_rewards/chosen': -2.8843331336975098, 'eval_rewards/rejected': -16.583276748657227, 'eval_rewards/accuracies': 1.0, 'eval_rewards/margins': 13.698944091796875, 'eval_logps/rejected': -206.18560791015625, 'eval_logps/chosen': -162.4845428466797, 'eval_logits/rejected': 144.94439697265625, 'eval_logits/chosen': 146.9715118408203, 'epoch': 17.39, 'eval_samples': 10}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python dpo_training.py \\\n",
        "    --model_type bloom \\\n",
        "    --model_name_or_path ./merged-sft \\\n",
        "    --train_file_dir ./data/reward \\\n",
        "    --validation_file_dir ./data/reward \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --max_steps 100 \\\n",
        "    --eval_steps 10 \\\n",
        "    --save_steps 50 \\\n",
        "    --max_source_length 128 \\\n",
        "    --max_target_length 128 \\\n",
        "    --output_dir outputs-dpo-v1 \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --fp16 True \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --remove_unused_columns False \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --cache_dir ./cache"
      ],
      "metadata": {
        "id": "7_4lSXOkjdju",
        "outputId": "651fdd5a-00f2-49a3-aee4-422a5dccbb70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 26M\n",
            "-rw-r--r-- 1 root root  660 Mar  8 05:51 adapter_config.json\n",
            "-rw-r--r-- 1 root root  13M Mar  8 05:51 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  730 Mar  8 05:51 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar  8 05:51 \u001b[0m\u001b[01;34mcheckpoint-100\u001b[0m/\n",
            "drwxr-xr-x 2 root root 4.0K Mar  8 05:49 \u001b[01;34mcheckpoint-50\u001b[0m/\n",
            "-rw-r--r-- 1 root root  558 Mar  8 05:51 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar  8 05:51 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar  8 05:48 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:51 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 1003 Mar  8 05:51 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:51 tokenizer.json\n",
            "-rw-r--r-- 1 root root  55K Mar  8 05:51 trainer_state.json\n",
            "-rw-r--r-- 1 root root 4.8K Mar  8 05:51 training_args.bin\n",
            "-rw-r--r-- 1 root root  194 Mar  8 05:51 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-dpo-v1"
      ],
      "metadata": {
        "id": "Mvh6d0Atjdju",
        "outputId": "f3a48ff1-903e-403e-fef6-064752edb7d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.bin`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ],
      "metadata": {
        "collapsed": false,
        "id": "RlsMblujjdju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ],
      "metadata": {
        "collapsed": false,
        "id": "65kRZ-9Mjdju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(model_type='bloom', base_model='merged-sft', tokenizer_path=None, lora_model='outputs-dpo-v1', resize_emb=False, output_dir='merged-dpo/')\n",
            "Base model: merged-sft\n",
            "LoRA model: outputs-dpo-v1\n",
            "Loading LoRA for causal language model\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to merged-dpo/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py --model_type bloom \\\n",
        "    --base_model merged-sft --lora_model outputs-dpo-v1 --output_dir merged-dpo/"
      ],
      "metadata": {
        "id": "61Ut6OoBjdju",
        "outputId": "db28ebc2-c82e-493a-cc65-26f714f89fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  795 Mar  8 05:51 config.json\n",
            "-rw-r--r-- 1 root root  132 Mar  8 05:51 generation_config.json\n",
            "-rw-r--r-- 1 root root 1.1G Mar  8 05:51 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root  552 Mar  8 05:51 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root  983 Mar  8 05:51 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  14M Mar  8 05:51 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-dpo/"
      ],
      "metadata": {
        "id": "C1u-Kz4Ijdjx",
        "outputId": "2582fcb1-1d2a-466f-f4a5-6aee41bae7ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"merged-sft\",\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BloomForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"masked_softmax_fusion\": true,\n",
            "  \"model_type\": \"bloom\",\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"offset_alibi\": 100,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"seq_length\": 2048,\n",
            "  \"skip_bias_add\": true,\n",
            "  \"skip_bias_add_qkv\": false,\n",
            "  \"slow_but_exact\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"unk_token_id\": 0,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250880\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-dpo/config.json"
      ],
      "metadata": {
        "id": "o0iwmQTbjdjx",
        "outputId": "444d53bc-4b1f-4153-b701-25efbf5bcacd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage3 偏好建模第一次训练完成。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1_JLg2yCjdjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**至此一个完整的训练流程演示完成。**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "frbRERHOjdjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-06-26T12:34:29.620609Z",
          "end_time": "2023-06-26T12:34:29.658428Z"
        },
        "id": "aMmbfXKwjdjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "collapsed": false,
        "id": "02kvz_qfjdjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-08 05:52:29.991003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-08 05:52:29.991059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-08 05:52:29.992387: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-08 05:52:31.607767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model_type='bloom', base_model='merged-dpo', lora_model='', tokenizer_path=None, template_name='vicuna', repetition_penalty=1.0, max_new_tokens=512, data_file=None, interactive=True, single_tune=False, do_sample=False, output_file='./predictions_result.jsonl', eval_batch_size=4, resize_emb=False, only_cpu=False, load_in_8bit=False, load_in_4bit=False)\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "BloomTokenizerFast(name_or_path='merged-dpo', vocab_size=250680, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.\n",
            "USER: 介绍下南京\n",
            "ASSISTANT: 顾名思义，顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思义顾名思\n",
            "USER: 1+1=\n",
            "ASSISTANT: 阿丽尔，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，\n",
            "USER: 介绍一下南京\n",
            "ASSISTANT:  无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛\n",
            "USER: 介绍一下南京\n",
            "ASSISTANT:  无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛人流无痛\n",
            "USER: 体温三十八度\n",
            "ASSISTANT:  你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，你好，\n",
            "USER: "
          ]
        }
      ],
      "source": [
        "!python inference.py --model_type bloom --base_model merged-dpo --interactive"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-06-26T12:34:47.802087Z",
          "end_time": "2023-06-26T12:35:00.864463Z"
        },
        "id": "8b6fBEeejdjy",
        "outputId": "c847718b-4cca-4180-ca6d-1672df38d6dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input:介绍下南京\n",
        "Response:  南京市位于江苏省西南部，是全国首批历史文化名城、国家中心城市和自由贸易试验区。\n",
        "\n",
        "完。\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "0ZMlYl9Ejdjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "usNVuxs3jdjy"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}